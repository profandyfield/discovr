
R version 4.5.1 (2025-06-13) -- "Great Square Root"
Copyright (C) 2025 The R Foundation for Statistical Computing
Platform: x86_64-apple-darwin20

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> pkgname <- "performance"
> source(file.path(R.home("share"), "R", "examples-header.R"))
> options(warn = 1)
> library('performance')
> 
> base::assign(".oldSearch", base::search(), pos = 'CheckExEnv')
> base::assign(".old_wd", base::getwd(), pos = 'CheckExEnv')
> cleanEx()
> nameEx("binned_residuals")
> ### * binned_residuals
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: binned_residuals
> ### Title: Binned residuals for binomial logistic regression
> ### Aliases: binned_residuals
> 
> ### ** Examples
> 
> model <- glm(vs ~ wt + mpg, data = mtcars, family = "binomial")
> result <- binned_residuals(model)
> result
[31mWarning: Probably bad model fit. Only about 50% of the residuals are inside the error bounds.
[39m> 
> # look at the data frame
> as.data.frame(result)
                xbar        ybar n       x.lo       x.hi         se     CI_low
conf_int  0.03786483 -0.26905395 5 0.01744776 0.06917366 0.07079661 -0.5299658
conf_int1 0.09514191 -0.44334345 5 0.07087498 0.15160143 0.06530245 -0.7042553
conf_int2 0.25910531  0.03762945 6 0.17159955 0.35374001 1.02017708 -0.3293456
conf_int3 0.47954643 -0.19916717 5 0.38363314 0.54063600 1.16107852 -0.5994783
conf_int4 0.71108931  0.81563262 5 0.57299903 0.89141359 0.19814385  0.5547207
conf_int5 0.97119262 -0.23399465 6 0.91147360 0.99815623 0.77513642 -0.5525066
               CI_high group
conf_int  -0.008142076    no
conf_int1 -0.182431572    no
conf_int2  0.404604465   yes
conf_int3  0.201143953   yes
conf_int4  1.076544495    no
conf_int5  0.084517267   yes
> 
> ## Don't show: 
> if (insight::check_if_installed("see", minimum_version = "0.9.1", quietly = TRUE)) withAutoprint({ # examplesIf
+ ## End(Don't show)
+ ## Don't show: 
+ }) # examplesIf
> ## End(Don't show)
> 
> 
> 
> cleanEx()
> nameEx("check_autocorrelation")
> ### * check_autocorrelation
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: check_autocorrelation
> ### Title: Check model for independence of residuals.
> ### Aliases: check_autocorrelation check_autocorrelation.default
> ###   check_autocorrelation.performance_simres
> 
> ### ** Examples
> 
> m <- lm(mpg ~ wt + cyl + gear + disp, data = mtcars)
> check_autocorrelation(m)
[32mOK: Residuals appear to be independent and not autocorrelated (p = 0.324).[39m> 
> 
> 
> cleanEx()
> nameEx("check_clusterstructure")
> ### * check_clusterstructure
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: check_clusterstructure
> ### Title: Check suitability of data for clustering
> ### Aliases: check_clusterstructure
> 
> ### ** Examples
> 
> 
> 
> 
> cleanEx()
> nameEx("check_collinearity")
> ### * check_collinearity
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: check_collinearity
> ### Title: Check for multicollinearity of model terms
> ### Aliases: check_collinearity multicollinearity
> ###   check_collinearity.default check_collinearity.glmmTMB
> ###   check_concurvity
> 
> ### ** Examples
> 
> m <- lm(mpg ~ wt + cyl + gear + disp, data = mtcars)
> check_collinearity(m)
[34m# Check for Multicollinearity
[39m
[32mLow Correlation

[39m Term  VIF    VIF 95% CI adj. VIF Tolerance Tolerance 95% CI
 gear 1.53 [1.19,  2.51]     1.24      0.65     [0.40, 0.84]

[33mModerate Correlation

[39m Term  VIF    VIF 95% CI adj. VIF Tolerance Tolerance 95% CI
   wt 5.05 [3.21,  8.41]     2.25      0.20     [0.12, 0.31]
  cyl 5.41 [3.42,  9.04]     2.33      0.18     [0.11, 0.29]
 disp 9.97 [6.08, 16.85]     3.16      0.10     [0.06, 0.16]
> 
> ## Don't show: 
> if (insight::check_if_installed("see", minimum_version = "0.9.1", quietly = TRUE)) withAutoprint({ # examplesIf
+ ## End(Don't show)
+ # plot results
+ x <- check_collinearity(m)
+ plot(x)
+ ## Don't show: 
+ }) # examplesIf
> x <- check_collinearity(m)
> plot(x)
> ## End(Don't show)
> 
> 
> 
> cleanEx()
> nameEx("check_convergence")
> ### * check_convergence
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: check_convergence
> ### Title: Convergence test for mixed effects models
> ### Aliases: check_convergence
> 
> ### ** Examples
> 
> ## Don't show: 
> if (require("lme4") && require("glmmTMB")) withAutoprint({ # examplesIf
+ ## End(Don't show)
+ data(cbpp, package = "lme4")
+ set.seed(1)
+ cbpp$x <- rnorm(nrow(cbpp))
+ cbpp$x2 <- runif(nrow(cbpp))
+ 
+ model <- lme4::glmer(
+   cbind(incidence, size - incidence) ~ period + x + x2 + (1 + x | herd),
+   data = cbpp,
+   family = binomial()
+ )
+ 
+ check_convergence(model)
+ 
+ ## Don't show: 
+ }) # examplesIf
Loading required package: lme4
Loading required package: Matrix
Loading required package: glmmTMB
Warning in check_dep_version(dep_pkg = "TMB") :
  package version mismatch: 
glmmTMB was built with TMB package version 1.9.17
Current TMB package version is 1.9.19
Please re-install glmmTMB from source or restore original â€˜TMBâ€™ package (see '?reinstalling' for more information)
> data(cbpp, package = "lme4")
> set.seed(1)
> cbpp$x <- rnorm(nrow(cbpp))
> cbpp$x2 <- runif(nrow(cbpp))
> model <- lme4::glmer(cbind(incidence, size - incidence) ~ period + x + 
+     x2 + (1 + x | herd), data = cbpp, family = binomial())
boundary (singular) fit: see help('isSingular')
> check_convergence(model)
[1] TRUE
attr(,"gradient")
[1] NA
> ## End(Don't show)
> 
> 
> 
> cleanEx()

detaching â€˜package:glmmTMBâ€™, â€˜package:lme4â€™, â€˜package:Matrixâ€™

> nameEx("check_dag")
> ### * check_dag
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: check_dag
> ### Title: Check correct model adjustment for identifying causal effects
> ### Aliases: check_dag as.dag
> 
> ### ** Examples
> 
> ## Don't show: 
> if (all(insight::check_if_installed(c("ggdag", "dagitty", "see"), quietly = TRUE))) withAutoprint({ # examplesIf
+ ## End(Don't show)
+ # no adjustment needed
+ check_dag(
+   y ~ x + b,
+   outcome = "y",
+   exposure = "x"
+ )
+ 
+ # incorrect adjustment
+ dag <- check_dag(
+   y ~ x + b + c,
+   x ~ b,
+   outcome = "y",
+   exposure = "x"
+ )
+ dag
+ plot(dag)
+ 
+ # After adjusting for `b`, the model is correctly specified
+ dag <- check_dag(
+   y ~ x + b + c,
+   x ~ b,
+   outcome = "y",
+   exposure = "x",
+   adjusted = "b"
+ )
+ dag
+ 
+ # using formula interface for arguments "outcome", "exposure" and "adjusted"
+ check_dag(
+   y ~ x + b + c,
+   x ~ b,
+   outcome = ~y,
+   exposure = ~x,
+   adjusted = ~ b + c
+ )
+ 
+ # if not provided, "outcome" is taken from first formula, same for "exposure"
+ # thus, we can simplify the above expression to
+ check_dag(
+   y ~ x + b + c,
+   x ~ b,
+   adjusted = ~ b + c
+ )
+ 
+ # use specific layout for the DAG
+ dag <- check_dag(
+   score ~ exp + b + c,
+   exp ~ b,
+   outcome = "score",
+   exposure = "exp",
+   coords = list(
+     # x-coordinates for all nodes
+     x = c(score = 5, exp = 4, b = 3, c = 3),
+     # y-coordinates for all nodes
+     y = c(score = 3, exp = 3, b = 2, c = 4)
+   )
+ )
+ plot(dag)
+ 
+ # alternative way of providing the coordinates
+ dag <- check_dag(
+   score ~ exp + b + c,
+   exp ~ b,
+   outcome = "score",
+   exposure = "exp",
+   coords = list(
+     # x/y coordinates for each node
+     score = c(5, 3),
+     exp = c(4, 3),
+     b = c(3, 2),
+     c = c(3, 4)
+   )
+ )
+ plot(dag)
+ 
+ # Objects returned by `check_dag()` can be used with "ggdag" or "dagitty"
+ ggdag::ggdag_status(dag)
+ 
+ # Using a model object to extract information about outcome,
+ # exposure and adjusted variables
+ data(mtcars)
+ m <- lm(mpg ~ wt + gear + disp + cyl, data = mtcars)
+ dag <- check_dag(
+   m,
+   wt ~ disp + cyl,
+   wt ~ am
+ )
+ dag
+ plot(dag)
+ ## Don't show: 
+ }) # examplesIf
> check_dag(y ~ x + b, outcome = "y", exposure = "x")
[34m# Check for correct adjustment sets[39m
- Outcome: y
- Exposure: x

[34mIdentification of direct and total effects

[39m[32mModel is correctly specified.[39m
No adjustment needed to estimate the direct and total effect of `x` on `y`.

> dag <- check_dag(y ~ x + b + c, x ~ b, outcome = "y", exposure = "x")
> dag
[34m# Check for correct adjustment sets[39m
- Outcome: y
- Exposure: x

[34mIdentification of direct and total effects

[39m[31mIncorrectly adjusted![39m
To estimate the direct and total effect, [3mat least[23m adjust for [33m`b`[39m. Currently, the model does not adjust for any variables.

> plot(dag)
> dag <- check_dag(y ~ x + b + c, x ~ b, outcome = "y", exposure = "x", 
+     adjusted = "b")
> dag
[34m# Check for correct adjustment sets[39m
- Outcome: y
- Exposure: x
- Adjustment: b

[34mIdentification of direct and total effects

[39m[32mModel is correctly specified.[39m
All minimal sufficient adjustments to estimate the direct and total effect were done.

> check_dag(y ~ x + b + c, x ~ b, outcome = ~y, exposure = ~x, adjusted = ~b + 
+     c)
[34m# Check for correct adjustment sets[39m
- Outcome: y
- Exposure: x
- Adjustments: b and c

[34mIdentification of direct and total effects

[39m[32mModel is correctly specified.[39m
All minimal sufficient adjustments to estimate the direct and total effect were done.

> check_dag(y ~ x + b + c, x ~ b, adjusted = ~b + c)
[34m# Check for correct adjustment sets[39m
- Outcome: y
- Exposure: x
- Adjustments: b and c

[34mIdentification of direct and total effects

[39m[32mModel is correctly specified.[39m
All minimal sufficient adjustments to estimate the direct and total effect were done.

> dag <- check_dag(score ~ exp + b + c, exp ~ b, outcome = "score", exposure = "exp", 
+     coords = list(x = c(score = 5, exp = 4, b = 3, c = 3), y = c(score = 3, exp = 3, 
+         b = 2, c = 4)))
> plot(dag)
> dag <- check_dag(score ~ exp + b + c, exp ~ b, outcome = "score", exposure = "exp", 
+     coords = list(score = c(5, 3), exp = c(4, 3), b = c(3, 2), c = c(3, 4)))
> plot(dag)
> ggdag::ggdag_status(dag)
> data(mtcars)
> m <- lm(mpg ~ wt + gear + disp + cyl, data = mtcars)
> dag <- check_dag(m, wt ~ disp + cyl, wt ~ am)
> dag
[34m# Check for correct adjustment sets[39m
- Outcome: mpg
- Exposure: wt
- Adjustments: cyl, disp and gear

[34mIdentification of direct and total effects

[39m[32mModel is correctly specified.[39m
All minimal sufficient adjustments to estimate the direct and total effect were done.

> plot(dag)
> ## End(Don't show)
> 
> 
> 
> cleanEx()
> nameEx("check_distribution")
> ### * check_distribution
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: check_distribution
> ### Title: Classify the distribution of a model-family using machine
> ###   learning
> ### Aliases: check_distribution
> 
> ### ** Examples
> 
> ## Don't show: 
> if (all(insight::check_if_installed(c("lme4", "parameters", "randomForest"), quietly = TRUE))) withAutoprint({ # examplesIf
+ ## End(Don't show)
+ data(sleepstudy, package = "lme4")
+ model <<- lme4::lmer(Reaction ~ Days + (Days | Subject), sleepstudy)
+ check_distribution(model)
+ ## Don't show: 
+ }) # examplesIf
> data(sleepstudy, package = "lme4")
> model <<- lme4::lmer(Reaction ~ Days + (Days | Subject), sleepstudy)
> check_distribution(model)
[34m# Distribution of Model Family

[39m[31mPredicted Distribution of Residuals

[39m               Distribution Probability
                     cauchy         91%
                      gamma          6%
 neg. binomial (zero-infl.)          3%
[31m
Predicted Distribution of Response

[39m Distribution Probability
    lognormal         66%
        gamma         34%
> ## End(Don't show)
> ## Don't show: 
> if (all(insight::check_if_installed(c("see", "patchwork", "randomForest"), quietly = TRUE))) withAutoprint({ # examplesIf
+ ## End(Don't show)
+ plot(check_distribution(model))
+ ## Don't show: 
+ }) # examplesIf
> plot(check_distribution(model))
> ## End(Don't show)
> 
> 
> 
> cleanEx()
> nameEx("check_factorstructure")
> ### * check_factorstructure
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: check_factorstructure
> ### Title: Check suitability of data for Factor Analysis (FA) with
> ###   Bartlett's Test of Sphericity and KMO
> ### Aliases: check_factorstructure check_kmo check_sphericity_bartlett
> 
> ### ** Examples
> 
> library(performance)
> 
> check_factorstructure(mtcars)
[34m# Is the data suitable for Factor Analysis?

[39m[32m
  - Sphericity: Bartlett's test of sphericity suggests that there is sufficient significant correlation in the data for factor analysis (Chisq(55) = 408.01, p < .001).
  - KMO: The Kaiser, Meyer, Olkin (KMO) overall measure of sampling adequacy suggests that data seems appropriate for factor analysis (KMO = 0.83). The individual KMO scores are: mpg (0.93), cyl (0.90), disp (0.76), hp (0.84), drat (0.95), wt (0.74), qsec (0.74), vs (0.91), am (0.88), gear (0.85), carb (0.62).[39m> 
> # One can also pass a correlation matrix
> r <- cor(mtcars)
> check_factorstructure(r, n = nrow(mtcars))
[34m# Is the data suitable for Factor Analysis?

[39m[32m
  - Sphericity: Bartlett's test of sphericity suggests that there is sufficient significant correlation in the data for factor analysis (Chisq(55) = 408.01, p < .001).
  - KMO: The Kaiser, Meyer, Olkin (KMO) overall measure of sampling adequacy suggests that data seems appropriate for factor analysis (KMO = 0.83). The individual KMO scores are: mpg (0.93), cyl (0.90), disp (0.76), hp (0.84), drat (0.95), wt (0.74), qsec (0.74), vs (0.91), am (0.88), gear (0.85), carb (0.62).[39m> 
> 
> 
> 
> cleanEx()
> nameEx("check_group_variation")
> ### * check_group_variation
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: check_group_variation
> ### Title: Check variables for within- and/or between-group variation
> ### Aliases: check_group_variation check_group_variation.default
> ###   check_group_variation.data.frame summary.check_group_variation
> 
> ### ** Examples
> 
> data(npk)
> check_group_variation(npk, by = "block")
[34mCheck block variation[39m

Variable | Variation |  Design
------------------------------
N        |    within | crossed
P        |    within | crossed
K        |    within | crossed
yield    |      both |        
> 
> data(iris)
> check_group_variation(iris, by = "Species")
[34mCheck Species variation[39m

Variable     | Variation | Design
---------------------------------
Sepal.Length |      both |       
Sepal.Width  |      both |       
Petal.Length |      both |       
Petal.Width  |      both |       
> 
> data(ChickWeight)
> check_group_variation(ChickWeight, by = "Chick")
[34mCheck Chick variation[39m

Variable | Variation | Design
-----------------------------
weight   |      both |       
Time     |      both |       
Diet     |   between |       
> 
> # A subset of mlmRev::egsingle
> egsingle <- data.frame(
+   schoolid = factor(rep(c("2020", "2820"), times = c(18, 6))),
+   lowinc = rep(c(TRUE, FALSE), times = c(18, 6)),
+   childid = factor(rep(
+     c("288643371", "292020281", "292020361", "295341521"),
+     each = 6
+   )),
+   female = rep(c(TRUE, FALSE), each = 12),
+   year = rep(1:6, times = 4),
+   math = c(
+     -3.068, -1.13, -0.921, 0.463, 0.021, 2.035,
+     -2.732, -2.097, -0.988, 0.227, 0.403, 1.623,
+     -2.732, -1.898, -0.921, 0.587, 1.578, 2.3,
+     -2.288, -2.162, -1.631, -1.555, -0.725, 0.097
+   )
+ )
> 
> result <- check_group_variation(
+   egsingle,
+   by = c("schoolid", "childid"),
+   include_by = TRUE
+ )
> result
[34mCheck schoolid variation[39m

Variable | Variation | Design
-----------------------------
childid  |      both | nested
lowinc   |   between | nested
female   |      both |       
year     |    within |       
math     |      both |       

[34mCheck childid variation[39m

Variable | Variation | Design
-----------------------------
schoolid |   between |       
lowinc   |   between |       
female   |   between |       
year     |    within |       
math     |      both |       
> 
> summary(result)
Possible heterogeneity bias due to following predictors:
[31m- childid:
  math
- schoolid: childid, female, math[39m
> 
> ## Don't show: 
> if (insight::check_if_installed("lme4", quietly = TRUE)) withAutoprint({ # examplesIf
+ ## End(Don't show)
+ 
+ data(sleepstudy, package = "lme4")
+ check_group_variation(sleepstudy, select = "Days", by = "Subject")
+ 
+ # Or
+ mod <- lme4::lmer(Reaction ~ Days + (Days | Subject), data = sleepstudy)
+ result <- check_group_variation(mod)
+ result
+ 
+ summary(result)
+ ## Don't show: 
+ }) # examplesIf
> data(sleepstudy, package = "lme4")
> check_group_variation(sleepstudy, select = "Days", by = "Subject")
[34mCheck Subject variation[39m

Variable | Variation | Design
-----------------------------
Days     |    within |       
> mod <- lme4::lmer(Reaction ~ Days + (Days | Subject), data = sleepstudy)
> result <- check_group_variation(mod)
> result
[34mCheck Subject variation[39m

Variable | Variation | Design
-----------------------------
Days     |    within |       
> summary(result)
[32mNo predictor found that could cause heterogeneity bias.[39m
> ## End(Don't show)
> 
> 
> 
> cleanEx()
> nameEx("check_heterogeneity_bias")
> ### * check_heterogeneity_bias
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: check_heterogeneity_bias
> ### Title: Check model predictor for heterogeneity bias _(Deprecated)_
> ### Aliases: check_heterogeneity_bias
> 
> ### ** Examples
> 
> data(iris)
> iris$ID <- sample(1:4, nrow(iris), replace = TRUE) # fake-ID
> check_heterogeneity_bias(iris, select = c("Sepal.Length", "Petal.Length"), by = "ID")
`check_heterogeneity_bias()` is deprecated. Please use
  `check_group_variation()` instead.
Possible heterogeneity bias due to following predictors: [31mSepal.Length, Petal.Length[39m
> 
> 
> 
> cleanEx()
> nameEx("check_heteroscedasticity")
> ### * check_heteroscedasticity
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: check_heteroscedasticity
> ### Title: Check model for (non-)constant error variance
> ### Aliases: check_heteroscedasticity check_heteroskedasticity
> 
> ### ** Examples
> 
> m <<- lm(mpg ~ wt + cyl + gear + disp, data = mtcars)
> check_heteroscedasticity(m)
[31mWarning: Heteroscedasticity (non-constant error variance) detected (p = 0.042).
[39m> 
> # plot results
> ## Don't show: 
> if (insight::check_if_installed("see", minimum_version = "0.9.1", quietly = TRUE)) withAutoprint({ # examplesIf
+ ## End(Don't show)
+ x <- check_heteroscedasticity(m)
+ plot(x)
+ ## Don't show: 
+ }) # examplesIf
> x <- check_heteroscedasticity(m)
> plot(x)
> ## End(Don't show)
> 
> 
> 
> cleanEx()
> nameEx("check_homogeneity")
> ### * check_homogeneity
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: check_homogeneity
> ### Title: Check model for homogeneity of variances
> ### Aliases: check_homogeneity check_homogeneity.afex_aov
> 
> ### ** Examples
> 
> model <<- lm(len ~ supp + dose, data = ToothGrowth)
> check_homogeneity(model)
[32mOK: There is not clear evidence for different variances across groups (Bartlett Test, p = 0.226).
[39m> 
> # plot results
> ## Don't show: 
> if (insight::check_if_installed("see", minimum_version = "0.9.1", quietly = TRUE)) withAutoprint({ # examplesIf
+ ## End(Don't show)
+ result <- check_homogeneity(model)
+ plot(result)
+ ## Don't show: 
+ }) # examplesIf
> result <- check_homogeneity(model)
> plot(result)
> ## End(Don't show)
> 
> 
> 
> cleanEx()
> nameEx("check_itemscale")
> ### * check_itemscale
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: check_itemscale
> ### Title: Describe Properties of Item Scales
> ### Aliases: check_itemscale
> 
> ### ** Examples
> 
> ## Don't show: 
> if (require("parameters") && require("psych")) withAutoprint({ # examplesIf
+ ## End(Don't show)
+ # data generation from '?prcomp', slightly modified
+ C <- chol(S <- toeplitz(0.9^(0:15)))
+ set.seed(17)
+ X <- matrix(rnorm(1600), 100, 16)
+ Z <- X %*% C
+ 
+ pca <- parameters::principal_components(
+   as.data.frame(Z),
+   rotation = "varimax",
+   n = 3
+ )
+ pca
+ check_itemscale(pca)
+ 
+ # as data frame
+ check_itemscale(
+   as.data.frame(Z),
+   factor_index = parameters::closest_component(pca)
+ )
+ ## Don't show: 
+ }) # examplesIf
Loading required package: parameters
Loading required package: psych
> C <- chol(S <- toeplitz(0.9^(0:15)))
> set.seed(17)
> X <- matrix(rnorm(1600), 100, 16)
> Z <- X %*% C
> pca <- parameters::principal_components(as.data.frame(Z), rotation = "varimax", 
+     n = 3)
> pca
[34m# Rotated loadings from Principal Component Analysis (varimax-rotation)[39m

Variable |  RC3 |  RC1 |  RC2 | Complexity | Uniqueness |  MSA
--------------------------------------------------------------
V1       | 0.85 | 0.17 | 0.20 |       1.20 |       0.21 | 0.90
V2       | 0.89 | 0.25 | 0.22 |       1.28 |       0.11 | 0.90
V3       | 0.91 | 0.26 | 0.17 |       1.23 |       0.07 | 0.89
V4       | 0.88 | 0.33 | 0.13 |       1.33 |       0.10 | 0.91
V5       | 0.82 | 0.41 | 0.14 |       1.55 |       0.14 | 0.94
V6       | 0.68 | 0.59 | 0.18 |       2.12 |       0.15 | 0.92
V7       | 0.57 | 0.74 | 0.20 |       2.04 |       0.09 | 0.93
V8       | 0.44 | 0.81 | 0.20 |       1.67 |       0.11 | 0.95
V9       | 0.33 | 0.84 | 0.32 |       1.61 |       0.09 | 0.93
V10      | 0.29 | 0.85 | 0.33 |       1.55 |       0.09 | 0.92
V11      | 0.30 | 0.79 | 0.42 |       1.86 |       0.11 | 0.92
V12      | 0.27 | 0.68 | 0.57 |       2.28 |       0.15 | 0.90
V13      | 0.20 | 0.55 | 0.71 |       2.06 |       0.15 | 0.90
V14      | 0.21 | 0.36 | 0.86 |       1.48 |       0.09 | 0.91
V15      | 0.20 | 0.23 | 0.91 |       1.23 |       0.08 | 0.88
V16      | 0.11 | 0.15 | 0.90 |       1.09 |       0.15 | 0.87
[33m
The 3 principal components (varimax rotation) accounted for 88.19% of the total variance of the original data (RC3 = 32.81%, RC1 = 31.24%, RC2 = 24.14%).
[39m> check_itemscale(pca)
[34m# Description of (Sub-)Scales[39m[31m
Component 1[39m

Item | Missings |  Mean |   SD | Skewness | Difficulty | Discrimination | alpha if deleted
------------------------------------------------------------------------------------------
V1   |        0 | -0.02 | 1.06 |    -0.49 |      -0.01 |           0.80 |             0.96
V2   |        0 | -0.05 | 1.05 |    -0.29 |      -0.02 |           0.90 |             0.95
V3   |        0 |  0.00 | 1.10 |    -0.77 |       0.00 |           0.94 |             0.95
V4   |        0 |  0.00 | 1.10 |    -0.82 |       0.00 |           0.92 |             0.95
V5   |        0 | -0.07 | 1.09 |    -0.29 |      -0.02 |           0.90 |             0.95
V6   |        0 | -0.04 | 1.13 |    -0.27 |      -0.01 |           0.83 |             0.96
[33m
Mean inter-item-correlation = 0.813  Cronbach's alpha = 0.963[39m
[31m
Component 2[39m

Item | Missings |  Mean |   SD | Skewness | Difficulty | Discrimination | alpha if deleted
------------------------------------------------------------------------------------------
V7   |        0 | -0.01 | 1.07 |     0.01 |       0.00 |           0.87 |             0.97
V8   |        0 |  0.02 | 0.96 |     0.23 |       0.01 |           0.89 |             0.96
V9   |        0 |  0.04 | 0.98 |     0.37 |       0.01 |           0.93 |             0.96
V10  |        0 |  0.08 | 1.00 |     0.18 |       0.02 |           0.93 |             0.96
V11  |        0 |  0.02 | 1.03 |     0.18 |       0.01 |           0.92 |             0.96
V12  |        0 |  0.00 | 1.04 |     0.27 |       0.00 |           0.84 |             0.97
[33m
Mean inter-item-correlation = 0.840  Cronbach's alpha = 0.969[39m
[31m
Component 3[39m

Item | Missings |  Mean |   SD | Skewness | Difficulty | Discrimination | alpha if deleted
------------------------------------------------------------------------------------------
V13  |        0 |  0.04 | 0.95 |     0.10 |       0.01 |           0.81 |             0.95
V14  |        0 | -0.02 | 0.96 |     0.24 |      -0.01 |           0.93 |             0.91
V15  |        0 | -0.03 | 0.94 |     0.41 |      -0.01 |           0.92 |             0.91
V16  |        0 |  0.03 | 0.96 |     0.28 |       0.01 |           0.82 |             0.94
[33m
Mean inter-item-correlation = 0.811  Cronbach's alpha = 0.945[39m> check_itemscale(as.data.frame(Z), factor_index = parameters::closest_component(pca))
[34m# Description of (Sub-)Scales[39m[31m
Component 1[39m

Item | Missings |  Mean |   SD | Skewness | Difficulty | Discrimination | alpha if deleted
------------------------------------------------------------------------------------------
V1   |        0 | -0.02 | 1.06 |    -0.49 |      -0.01 |           0.80 |             0.96
V2   |        0 | -0.05 | 1.05 |    -0.29 |      -0.02 |           0.90 |             0.95
V3   |        0 |  0.00 | 1.10 |    -0.77 |       0.00 |           0.94 |             0.95
V4   |        0 |  0.00 | 1.10 |    -0.82 |       0.00 |           0.92 |             0.95
V5   |        0 | -0.07 | 1.09 |    -0.29 |      -0.02 |           0.90 |             0.95
V6   |        0 | -0.04 | 1.13 |    -0.27 |      -0.01 |           0.83 |             0.96
[33m
Mean inter-item-correlation = 0.813  Cronbach's alpha = 0.963[39m
[31m
Component 2[39m

Item | Missings |  Mean |   SD | Skewness | Difficulty | Discrimination | alpha if deleted
------------------------------------------------------------------------------------------
V7   |        0 | -0.01 | 1.07 |     0.01 |       0.00 |           0.87 |             0.97
V8   |        0 |  0.02 | 0.96 |     0.23 |       0.01 |           0.89 |             0.96
V9   |        0 |  0.04 | 0.98 |     0.37 |       0.01 |           0.93 |             0.96
V10  |        0 |  0.08 | 1.00 |     0.18 |       0.02 |           0.93 |             0.96
V11  |        0 |  0.02 | 1.03 |     0.18 |       0.01 |           0.92 |             0.96
V12  |        0 |  0.00 | 1.04 |     0.27 |       0.00 |           0.84 |             0.97
[33m
Mean inter-item-correlation = 0.840  Cronbach's alpha = 0.969[39m
[31m
Component 3[39m

Item | Missings |  Mean |   SD | Skewness | Difficulty | Discrimination | alpha if deleted
------------------------------------------------------------------------------------------
V13  |        0 |  0.04 | 0.95 |     0.10 |       0.01 |           0.81 |             0.95
V14  |        0 | -0.02 | 0.96 |     0.24 |      -0.01 |           0.93 |             0.91
V15  |        0 | -0.03 | 0.94 |     0.41 |      -0.01 |           0.92 |             0.91
V16  |        0 |  0.03 | 0.96 |     0.28 |       0.01 |           0.82 |             0.94
[33m
Mean inter-item-correlation = 0.811  Cronbach's alpha = 0.945[39m> ## End(Don't show)
> 
> 
> 
> cleanEx()

detaching â€˜package:psychâ€™, â€˜package:parametersâ€™

> nameEx("check_model")
> ### * check_model
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: check_model
> ### Title: Visual check of model assumptions
> ### Aliases: check_model check_model.default
> 
> ### ** Examples
> 
> ## Don't show: 
> if (require("lme4") && FALSE) withAutoprint({ # examplesIf
+ ## End(Don't show)
+ ## Don't show: 
+ }) # examplesIf
Loading required package: lme4
Loading required package: Matrix
> ## End(Don't show)
> 
> 
> 
> cleanEx()

detaching â€˜package:lme4â€™, â€˜package:Matrixâ€™

> nameEx("check_multimodal")
> ### * check_multimodal
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: check_multimodal
> ### Title: Check if a distribution is unimodal or multimodal
> ### Aliases: check_multimodal
> 
> ### ** Examples
> 
> ## Don't show: 
> if (require("multimode") && require("mclust")) withAutoprint({ # examplesIf
+ ## End(Don't show)
+ ## Don't show: 
+ }) # examplesIf
Loading required package: multimode
Loading required package: mclust
Package 'mclust' version 6.1.2
Type 'citation("mclust")' for citing this R package in publications.
> ## End(Don't show)
> 
> 
> 
> cleanEx()

detaching â€˜package:mclustâ€™, â€˜package:multimodeâ€™

> nameEx("check_normality")
> ### * check_normality
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: check_normality
> ### Title: Check model for (non-)normality of residuals.
> ### Aliases: check_normality check_normality.merMod
> 
> ### ** Examples
> 
> ## Don't show: 
> if (insight::check_if_installed("see", minimum_version = "0.9.1", quietly = TRUE)) withAutoprint({ # examplesIf
+ ## End(Don't show)
+ m <<- lm(mpg ~ wt + cyl + gear + disp, data = mtcars)
+ check_normality(m)
+ 
+ # plot results
+ x <- check_normality(m)
+ plot(x)
+ 
+ ## Don't show: 
+ }) # examplesIf
> m <<- lm(mpg ~ wt + cyl + gear + disp, data = mtcars)
> check_normality(m)
[32mOK: residuals appear as normally distributed (p = 0.230).
[39m> x <- check_normality(m)
> plot(x)
> ## End(Don't show)
> 
> 
> 
> cleanEx()
> nameEx("check_outliers")
> ### * check_outliers
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: check_outliers
> ### Title: Outliers detection (check for influential observations)
> ### Aliases: check_outliers check_outliers.default check_outliers.numeric
> ###   check_outliers.data.frame check_outliers.performance_simres
> 
> ### ** Examples
> 
> data <- mtcars # Size nrow(data) = 32
> 
> # For single variables ------------------------------------------------------
> # Find all observations beyond +/- 2 SD
> outliers_list <- check_outliers(data$mpg, method = "zscore", threshold = 2)
> outliers_list # Show the row index of the outliers
[33m2 outliers detected: cases 18, 20.
- Based on the following method and threshold: zscore (2).
- For variable: data$mpg.
[39m
-----------------------------------------------------------------------------
Outliers per variable (zscore): 

$`data$mpg`
   Row Distance_Zscore
18  18        2.042389
20  20        2.291272

> as.numeric(outliers_list) # The object is a binary vector...
 [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0
> filtered_data <- data[!outliers_list, ] # And can be used to filter a data frame
> nrow(filtered_data) # New size, 30 (2 outliers removed)
[1] 30
> 
> 
> # For dataframes ------------------------------------------------------
> check_outliers(data, threshold = 2) # It works the same way on data frames
[33m32 outliers detected: cases 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,
  14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31,
  32.
- Based on the following method and threshold: mahalanobis (2).
- For variables: mpg, cyl, disp, hp, drat, wt, qsec, vs, am, gear, carb.[39m> 
> # You can also use multiple methods at once
> outliers_list <- check_outliers(data, method = c(
+   "mahalanobis",
+   "iqr",
+   "zscore"
+ ))
> outliers_list
[32mOK: No outliers detected.
- Based on the following methods and thresholds: mahalanobis (3.291), iqr (2), zscore (31.264).
- For variables: mpg, cyl, disp, hp, drat, wt, qsec, vs, am, gear, carb

[39m> 
> # Using `as.data.frame()`, we can access more details!
> outliers_info <- as.data.frame(outliers_list)
> head(outliers_info)
  Row Distance_Zscore Outlier_Zscore Distance_IQR Outlier_IQR
1   1        1.189901              0    0.4208483           0
2   2        1.189901              0    0.2941176           0
3   3        1.224858              0    0.5882353           0
4   4        1.122152              0    0.5882353           0
5   5        1.043081              0    0.3915954           0
6   6        1.564608              0    0.6809025           0
  Distance_Mahalanobis Outlier_Mahalanobis Outlier
1             8.946673                   0       0
2             8.287933                   0       0
3             8.937150                   0       0
4             6.096726                   0       0
5             5.429061                   0       0
6             8.877558                   0       0
> outliers_info$Outlier # Including the probability of being an outlier
 [1] 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000
 [8] 0.0000000 0.3333333 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000
[15] 0.0000000 0.3333333 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000
[22] 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000
[29] 0.0000000 0.0000000 0.3333333 0.0000000
> 
> # And we can be more stringent in our outliers removal process
> filtered_data <- data[outliers_info$Outlier < 0.1, ]
> 
> # We can run the function stratified by groups using `{datawizard}` package:
> group_iris <- datawizard::data_group(iris, "Species")
> check_outliers(group_iris)
[32mOK: No outliers detected.
- Based on the following method and threshold: mahalanobis (20).
- For variables: Sepal.Length, Sepal.Width, Petal.Length, Petal.Width

[39m> # nolint start
> ## Don't show: 
> if (all(insight::check_if_installed(c("bigutilsr", "MASS", "ICSOutlier", "ICS", "dbscan", "loo", "see"), quietly = TRUE))) withAutoprint({ # examplesIf
+ ## End(Don't show)
+ # nolint end
+ ## Don't show: 
+ }) # examplesIf
> ## End(Don't show)
> 
> 
> 
> cleanEx()
> nameEx("check_overdispersion")
> ### * check_overdispersion
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: check_overdispersion
> ### Title: Check overdispersion (and underdispersion) of GL(M)M's
> ### Aliases: check_overdispersion check_overdispersion.performance_simres
> 
> ### ** Examples
> 
> ## Don't show: 
> if (getRversion() >= "4.0.0" && require("glmmTMB")) withAutoprint({ # examplesIf
+ ## End(Don't show)
+ data(Salamanders, package = "glmmTMB")
+ m <- glm(count ~ spp + mined, family = poisson, data = Salamanders)
+ check_overdispersion(m)
+ ## Don't show: 
+ }) # examplesIf
Loading required package: glmmTMB
> data(Salamanders, package = "glmmTMB")
> m <- glm(count ~ spp + mined, family = poisson, data = Salamanders)
> check_overdispersion(m)
[34m# Overdispersion test

[39m       dispersion ratio =    2.946
  Pearson's Chi-Squared = 1873.710
                p-value =  < 0.001

Overdispersion detected.
> ## End(Don't show)
> 
> 
> 
> cleanEx()

detaching â€˜package:glmmTMBâ€™

> nameEx("check_predictions")
> ### * check_predictions
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: check_predictions
> ### Title: Posterior predictive checks
> ### Aliases: check_predictions check_predictions.default
> 
> ### ** Examples
> 
> ## Don't show: 
> if (insight::check_if_installed("see", minimum_version = "0.9.1", quietly = TRUE)) withAutoprint({ # examplesIf
+ ## End(Don't show)
+ # linear model
+ model <- lm(mpg ~ disp, data = mtcars)
+ check_predictions(model)
+ 
+ # discrete/integer outcome
+ set.seed(99)
+ d <- iris
+ d$skewed <- rpois(150, 1)
+ model <- glm(
+   skewed ~ Species + Petal.Length + Petal.Width,
+   family = poisson(),
+   data = d
+ )
+ check_predictions(model, type = "discrete_both")
+ ## Don't show: 
+ }) # examplesIf
> model <- lm(mpg ~ disp, data = mtcars)
> check_predictions(model)
Ignoring unknown labels:
â€¢ size : ""
> set.seed(99)
> d <- iris
> d$skewed <- rpois(150, 1)
> model <- glm(skewed ~ Species + Petal.Length + Petal.Width, family = poisson(), 
+     data = d)
> check_predictions(model, type = "discrete_both")
Ignoring unknown labels:
â€¢ size : ""
â€¢ alpha : ""
> ## End(Don't show)
> 
> 
> 
> cleanEx()
> nameEx("check_residuals")
> ### * check_residuals
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: check_residuals
> ### Title: Check distribution of simulated quantile residuals
> ### Aliases: check_residuals check_residuals.default
> 
> ### ** Examples
> 
> ## Don't show: 
> if (require("DHARMa")) withAutoprint({ # examplesIf
+ ## End(Don't show)
+ dat <- DHARMa::createData(sampleSize = 100, overdispersion = 0.5, family = poisson())
+ m <- glm(observedResponse ~ Environment1, family = poisson(), data = dat)
+ res <- simulate_residuals(m)
+ check_residuals(res)
+ ## Don't show: 
+ }) # examplesIf
Loading required package: DHARMa
This is DHARMa 0.4.7. For overview type '?DHARMa'. For recent changes, type news(package = 'DHARMa')
> dat <- DHARMa::createData(sampleSize = 100, overdispersion = 0.5, family = poisson())
> m <- glm(observedResponse ~ Environment1, family = poisson(), data = dat)
> res <- simulate_residuals(m)
> check_residuals(res)
[31mWarning: Non-uniformity of simulated residuals detected (p = 0.006).
[39m> ## End(Don't show)
> 
> 
> 
> cleanEx()

detaching â€˜package:DHARMaâ€™

> nameEx("check_singularity")
> ### * check_singularity
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: check_singularity
> ### Title: Check mixed models for boundary fits
> ### Aliases: check_singularity check_singularity.glmmTMB
> 
> ### ** Examples
> 
> ## Don't show: 
> if (require("lme4") && require("glmmTMB")) withAutoprint({ # examplesIf
+ ## End(Don't show)
+ data(sleepstudy, package = "lme4")
+ set.seed(123)
+ sleepstudy$mygrp <- sample(1:5, size = 180, replace = TRUE)
+ sleepstudy$mysubgrp <- NA
+ for (i in 1:5) {
+   filter_group <- sleepstudy$mygrp == i
+   sleepstudy$mysubgrp[filter_group] <-
+     sample(1:30, size = sum(filter_group), replace = TRUE)
+ }
+ 
+ model <- lme4::lmer(
+   Reaction ~ Days + (1 | mygrp / mysubgrp) + (1 | Subject),
+   data = sleepstudy
+ )
+ # any singular fits?
+ check_singularity(model)
+ # singular fit for which particular random effects terms?
+ check_singularity(model, check = "terms")
+ 
+ ## Not run: 
+ ##D # Fixing singularity issues using priors in glmmTMB
+ ##D # Example taken from `vignette("priors", package = "glmmTMB")`
+ ##D dat <- readRDS(system.file(
+ ##D   "vignette_data",
+ ##D   "gophertortoise.rds",
+ ##D   package = "glmmTMB"
+ ##D ))
+ ##D model <- glmmTMB::glmmTMB(
+ ##D   shells ~ prev + offset(log(Area)) + factor(year) + (1 | Site),
+ ##D   family = poisson,
+ ##D   data = dat
+ ##D )
+ ##D # singular fit
+ ##D check_singularity(model)
+ ##D 
+ ##D # impose Gamma prior on random effects parameters
+ ##D prior <- data.frame(
+ ##D   prior = "gamma(1, 2.5)", # mean can be 1, but even 1e8
+ ##D   class = "ranef" # for random effects
+ ##D )
+ ##D model_with_priors <- update(model, priors = prior)
+ ##D # no singular fit
+ ##D check_singularity(model_with_priors)
+ ## End(Not run)
+ ## Don't show: 
+ }) # examplesIf
Loading required package: lme4
Loading required package: Matrix
Loading required package: glmmTMB
> data(sleepstudy, package = "lme4")
> set.seed(123)
> sleepstudy$mygrp <- sample(1:5, size = 180, replace = TRUE)
> sleepstudy$mysubgrp <- NA
> for (i in 1:5) {
+     filter_group <- sleepstudy$mygrp == i
+     sleepstudy$mysubgrp[filter_group] <- sample(1:30, size = sum(filter_group), replace = TRUE)
+ }
> model <- lme4::lmer(Reaction ~ Days + (1 | mygrp/mysubgrp) + (1 | Subject), 
+     data = sleepstudy)
boundary (singular) fit: see help('isSingular')
> check_singularity(model)
[1] TRUE
> check_singularity(model, check = "terms")
mysubgrp:mygrp        Subject          mygrp 
          TRUE          FALSE          FALSE 
> ## End(Don't show)
> 
> 
> 
> cleanEx()

detaching â€˜package:glmmTMBâ€™, â€˜package:lme4â€™, â€˜package:Matrixâ€™

> nameEx("check_sphericity")
> ### * check_sphericity
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: check_sphericity
> ### Title: Check model for violation of sphericity
> ### Aliases: check_sphericity
> 
> ### ** Examples
> 
> ## Don't show: 
> if (require("car") && require("carData")) withAutoprint({ # examplesIf
+ ## End(Don't show)
+ data(Soils, package = "carData")
+ soils.mod <- lm(
+   cbind(pH, N, Dens, P, Ca, Mg, K, Na, Conduc) ~ Block + Contour * Depth,
+   data = Soils
+ )
+ 
+ check_sphericity(Manova(soils.mod))
+ ## Don't show: 
+ }) # examplesIf
Loading required package: car
Loading required package: carData
> data(Soils, package = "carData")
> soils.mod <- lm(cbind(pH, N, Dens, P, Ca, Mg, K, Na, Conduc) ~ Block + 
+     Contour * Depth, data = Soils)
> check_sphericity(Manova(soils.mod))
[32mOK: Data seems to be spherical (p > .999).
[39m> ## End(Don't show)
> 
> 
> 
> cleanEx()

detaching â€˜package:carâ€™, â€˜package:carDataâ€™

> nameEx("check_symmetry")
> ### * check_symmetry
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: check_symmetry
> ### Title: Check distribution symmetry
> ### Aliases: check_symmetry
> 
> ### ** Examples
> 
> V <- suppressWarnings(wilcox.test(mtcars$mpg))
> check_symmetry(V)
[32mOK: Data appears symmetrical (p = 0.119).
[39m> 
> 
> 
> 
> cleanEx()
> nameEx("check_zeroinflation")
> ### * check_zeroinflation
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: check_zeroinflation
> ### Title: Check for zero-inflation in count models
> ### Aliases: check_zeroinflation check_zeroinflation.default
> ###   check_zeroinflation.performance_simres
> 
> ### ** Examples
> 
> ## Don't show: 
> if (require("glmmTMB") && require("DHARMa")) withAutoprint({ # examplesIf
+ ## End(Don't show)
+ data(Salamanders, package = "glmmTMB")
+ m <- glm(count ~ spp + mined, family = poisson, data = Salamanders)
+ check_zeroinflation(m)
+ 
+ # for models with zero-inflation component, it's better to carry out
+ # the check for zero-inflation using simulated residuals
+ m <- glmmTMB::glmmTMB(
+   count ~ spp + mined,
+   ziformula = ~ mined + spp,
+   family = poisson,
+   data = Salamanders
+ )
+ res <- simulate_residuals(m)
+ check_zeroinflation(res)
+ ## Don't show: 
+ }) # examplesIf
Loading required package: glmmTMB
Loading required package: DHARMa
This is DHARMa 0.4.7. For overview type '?DHARMa'. For recent changes, type news(package = 'DHARMa')
> data(Salamanders, package = "glmmTMB")
> m <- glm(count ~ spp + mined, family = poisson, data = Salamanders)
> check_zeroinflation(m)
[34m# Check for zero-inflation

[39m   Observed zeros: 387
  Predicted zeros: 298
            Ratio: 0.77

Model is underfitting zeros (probable zero-inflation).
> m <- glmmTMB::glmmTMB(count ~ spp + mined, ziformula = ~mined + spp, family = poisson, 
+     data = Salamanders)
> res <- simulate_residuals(m)
> check_zeroinflation(res)
[34m# Check for zero-inflation

[39m   Observed zeros: 387
  Predicted zeros: 387
            Ratio: 1.00

Model seems ok, ratio of observed and predicted zeros is within the
  tolerance range (p > .999).
> ## End(Don't show)
> 
> 
> 
> cleanEx()

detaching â€˜package:DHARMaâ€™, â€˜package:glmmTMBâ€™

> nameEx("compare_performance")
> ### * compare_performance
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: compare_performance
> ### Title: Compare performance of different models
> ### Aliases: compare_performance
> 
> ### ** Examples
> 
> ## Don't show: 
> if (require("lme4")) withAutoprint({ # examplesIf
+ ## End(Don't show)
+ data(iris)
+ lm1 <- lm(Sepal.Length ~ Species, data = iris)
+ lm2 <- lm(Sepal.Length ~ Species + Petal.Length, data = iris)
+ lm3 <- lm(Sepal.Length ~ Species * Petal.Length, data = iris)
+ compare_performance(lm1, lm2, lm3)
+ compare_performance(lm1, lm2, lm3, rank = TRUE)
+ 
+ m1 <- lm(mpg ~ wt + cyl, data = mtcars)
+ m2 <- glm(vs ~ wt + mpg, data = mtcars, family = "binomial")
+ m3 <- lme4::lmer(Petal.Length ~ Sepal.Length + (1 | Species), data = iris)
+ compare_performance(m1, m2, m3)
+ ## Don't show: 
+ }) # examplesIf
Loading required package: lme4
Loading required package: Matrix
> data(iris)
> lm1 <- lm(Sepal.Length ~ Species, data = iris)
> lm2 <- lm(Sepal.Length ~ Species + Petal.Length, data = iris)
> lm3 <- lm(Sepal.Length ~ Species * Petal.Length, data = iris)
> compare_performance(lm1, lm2, lm3)
[34m# Comparison of Model Performance Indices[39m

Name | Model | AIC (weights) | AICc (weights) | BIC (weights) |    R2
---------------------------------------------------------------------
lm1  |    lm | 231.5 (<.001) |  231.7 (<.001) | 243.5 (<.001) | 0.619
lm2  |    lm | 106.2 (0.566) |  106.6 (0.611) | 121.3 (0.964) | 0.837
lm3  |    lm | 106.8 (0.434) |  107.6 (0.389) | 127.8 (0.036) | 0.840

Name | R2 (adj.) |  RMSE | Sigma
--------------------------------
lm1  |     0.614 | 0.510 | 0.515
lm2  |     0.833 | 0.333 | 0.338
lm3  |     0.835 | 0.330 | 0.336
> compare_performance(lm1, lm2, lm3, rank = TRUE)
[34m# Comparison of Model Performance Indices[39m

Name | Model |    R2 | R2 (adj.) |  RMSE | Sigma | AIC weights | AICc weights
-----------------------------------------------------------------------------
lm2  |    lm | 0.837 |     0.833 | 0.333 | 0.338 |       0.566 |        0.611
lm3  |    lm | 0.840 |     0.835 | 0.330 | 0.336 |       0.434 |        0.389
lm1  |    lm | 0.619 |     0.614 | 0.510 | 0.515 |    3.65e-28 |     4.23e-28

Name | BIC weights | Performance-Score
--------------------------------------
lm2  |       0.964 |            99.23%
lm3  |       0.036 |            77.70%
lm1  |    2.80e-27 |             0.00%
> m1 <- lm(mpg ~ wt + cyl, data = mtcars)
> m2 <- glm(vs ~ wt + mpg, data = mtcars, family = "binomial")
> m3 <- lme4::lmer(Petal.Length ~ Sepal.Length + (1 | Species), data = iris)
> compare_performance(m1, m2, m3)
When comparing models, please note that probably not all models were fit
  from same data.
[34m# Comparison of Model Performance Indices[39m

Name |   Model | AIC (weights) | AICc (weights) | BIC (weights) |  RMSE | Sigma
-------------------------------------------------------------------------------
m1   |      lm | 156.0 (<.001) |  157.5 (<.001) | 161.9 (<.001) | 2.444 | 2.568
m2   |     glm |  31.3 (>.999) |   32.2 (>.999) |  35.7 (>.999) | 0.359 | 1.000
m3   | lmerMod |  74.6 (<.001) |   74.9 (<.001) |  86.7 (<.001) | 0.279 | 0.283

Name |    R2 | R2 (adj.) | Tjur's R2 | Log_loss | Score_log | Score_spherical
-----------------------------------------------------------------------------
m1   | 0.830 |     0.819 |           |          |           |                
m2   |       |           |     0.478 |    0.395 |   -14.903 |           0.095
m3   |       |           |           |          |           |                

Name |   PCP | R2 (cond.) | R2 (marg.) |   ICC
----------------------------------------------
m1   |       |            |            |      
m2   | 0.743 |            |            |      
m3   |       |      0.972 |      0.096 | 0.969
> ## End(Don't show)
> 
> 
> 
> cleanEx()

detaching â€˜package:lme4â€™, â€˜package:Matrixâ€™

> nameEx("cronbachs_alpha")
> ### * cronbachs_alpha
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: cronbachs_alpha
> ### Title: Cronbach's Alpha for Items or Scales
> ### Aliases: cronbachs_alpha item_alpha cronbachs_alpha.data.frame
> 
> ### ** Examples
> 
> data(mtcars)
> x <- mtcars[, c("cyl", "gear", "carb", "hp")]
> cronbachs_alpha(x)
[1] 0.09463206
> 
> 
> 
> cleanEx()
> nameEx("display.performance_model")
> ### * display.performance_model
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: display.performance_model
> ### Title: Print tables in different output formats
> ### Aliases: display.performance_model print.performance_model
> ###   print_md.performance_model print_md.compare_performance
> 
> ### ** Examples
> 
> model <- lm(mpg ~ wt + cyl, data = mtcars)
> mp <- model_performance(model)
> display(mp)
[1] "|AIC   |  AICc |   BIC |   R2 | R2 (adj.) | RMSE | Sigma |"
[2] "|:-----|:-----:|:-----:|:----:|:---------:|:----:|:-----:|"
[3] "|156.0 | 157.5 | 161.9 | 0.83 |      0.82 | 2.44 |  2.57 |"
attr(,"format")
[1] "pipe"
attr(,"class")
[1] "knitr_kable" "character"  
> display(mp, digits = 3, ic_digits = 4)
[1] "|AIC      |     AICc |      BIC |    R2 | R2 (adj.) |  RMSE | Sigma |"
[2] "|:--------|:--------:|:--------:|:-----:|:---------:|:-----:|:-----:|"
[3] "|156.0101 | 157.4915 | 161.8730 | 0.830 |     0.819 | 2.444 | 2.568 |"
attr(,"format")
[1] "pipe"
attr(,"class")
[1] "knitr_kable" "character"  
> 
> 
> 
> cleanEx()
> nameEx("icc")
> ### * icc
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: icc
> ### Title: Intraclass Correlation Coefficient (ICC)
> ### Aliases: icc variance_decomposition
> 
> ### ** Examples
> 
> ## Don't show: 
> if (require("lme4")) withAutoprint({ # examplesIf
+ ## End(Don't show)
+ model <- lme4::lmer(Sepal.Length ~ Petal.Length + (1 | Species), data = iris)
+ icc(model)
+ 
+ # ICC for specific group-levels
+ data(sleepstudy, package = "lme4")
+ set.seed(12345)
+ sleepstudy$grp <- sample(1:5, size = 180, replace = TRUE)
+ sleepstudy$subgrp <- NA
+ for (i in 1:5) {
+   filter_group <- sleepstudy$grp == i
+   sleepstudy$subgrp[filter_group] <-
+     sample(1:30, size = sum(filter_group), replace = TRUE)
+ }
+ model <- lme4::lmer(
+   Reaction ~ Days + (1 | grp / subgrp) + (1 | Subject),
+   data = sleepstudy
+ )
+ icc(model, by_group = TRUE)
+ ## Don't show: 
+ }) # examplesIf
Loading required package: lme4
Loading required package: Matrix
> model <- lme4::lmer(Sepal.Length ~ Petal.Length + (1 | Species), data = iris)
> icc(model)
[34m# Intraclass Correlation Coefficient

[39m    Adjusted ICC: 0.910
  Unadjusted ICC: 0.311
> data(sleepstudy, package = "lme4")
> set.seed(12345)
> sleepstudy$grp <- sample(1:5, size = 180, replace = TRUE)
> sleepstudy$subgrp <- NA
> for (i in 1:5) {
+     filter_group <- sleepstudy$grp == i
+     sleepstudy$subgrp[filter_group] <- sample(1:30, size = sum(filter_group), replace = TRUE)
+ }
> model <- lme4::lmer(Reaction ~ Days + (1 | grp/subgrp) + (1 | Subject), 
+     data = sleepstudy)
> icc(model, by_group = TRUE)
[34m# ICC by Group

[39mGroup      |   ICC
------------------
subgrp:grp | 0.017
Subject    | 0.589
grp        | 0.001
> ## End(Don't show)
> 
> 
> 
> cleanEx()

detaching â€˜package:lme4â€™, â€˜package:Matrixâ€™

> nameEx("item_difficulty")
> ### * item_difficulty
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: item_difficulty
> ### Title: Difficulty of Questionnaire Items
> ### Aliases: item_difficulty
> 
> ### ** Examples
> 
> data(mtcars)
> x <- mtcars[, c("cyl", "gear", "carb", "hp")]
> item_difficulty(x)
[34mItem Difficulty[39m

Item | Difficulty | Ideal
-------------------------
cyl  |       0.02 |  0.50
gear |       0.01 |  0.50
carb |       0.01 |  0.50
hp   |       0.44 |  0.50
> 
> 
> 
> cleanEx()
> nameEx("item_discrimination")
> ### * item_discrimination
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: item_discrimination
> ### Title: Discrimination and Item-Total Correlation of Questionnaire Items
> ### Aliases: item_discrimination item_totalcor
> 
> ### ** Examples
> 
> data(mtcars)
> x <- mtcars[, c("cyl", "gear", "carb", "hp")]
> item_discrimination(x)
Some of the values are negative. Maybe affected items need to be
  reverse-coded, e.g. using `datawizard::reverse()`.
Item Discrimination

Item | Discrimination
---------------------
cyl  |           0.83
gear |          -0.13
carb |           0.75
hp   |           0.88
> item_totalcor(x)
Some of the values are negative. Maybe affected items need to be
  reverse-coded, e.g. using `datawizard::reverse()`.
Item-Total Correlation

Item | Total Correlation
------------------------
cyl  |              0.83
gear |             -0.12
carb |              0.76
hp   |              1.00
> 
> 
> 
> cleanEx()
> nameEx("item_intercor")
> ### * item_intercor
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: item_intercor
> ### Title: Mean Inter-Item-Correlation
> ### Aliases: item_intercor
> 
> ### ** Examples
> 
> data(mtcars)
> x <- mtcars[, c("cyl", "gear", "carb", "hp")]
> item_intercor(x)
[1] 0.294155
> 
> 
> 
> cleanEx()
> nameEx("item_omega")
> ### * item_omega
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: item_omega
> ### Title: McDonald's Omega for Items or Scales
> ### Aliases: item_omega item_omega.data.frame item_omega.matrix
> 
> ### ** Examples
> 
> ## Don't show: 
> if (insight::check_if_installed("parameters", quietly = TRUE)) withAutoprint({ # examplesIf
+ ## End(Don't show)
+ data(mtcars)
+ x <- mtcars[1:7]
+ result <- item_omega(x, n = 2)
+ 
+ result
+ 
+ as.numeric(result)
+ 
+ summary(result)
+ 
+ parameters::model_parameters(result)
+ ## Don't show: 
+ }) # examplesIf
> data(mtcars)
> x <- mtcars[1:7]
> result <- item_omega(x, n = 2)
Loading required namespace: GPArotation

Three factors are required for identification -- general factor loadings set to be equal. 
Proceed with caution. 
Think about redoing the analysis with alternative values of the 'option' setting.

> result
[34m# Reliability Coefficients[39m

Statistic            | Coefficient
----------------------------------
Alpha                |        0.93
G.6                  |        0.97
Omega (hierarchical) |        0.46
Omega (asymptotic H) |        0.47
Omega (total)        |        0.97
> as.numeric(result)
               Alpha                  G.6 Omega (hierarchical) 
           0.9315665            0.9662008            0.4610075 
Omega (asymptotic H)        Omega (total) 
           0.4745543            0.9714535 
> summary(result)
[34m# Omega Statistics[39m

Statistic            | Coefficient
----------------------------------
Alpha                |        0.93
G.6                  |        0.97
Omega (hierarchical) |        0.46
Omega (asymptotic H) |        0.47
Omega (total)        |        0.97

[34m# Omega Coefficients[39m

Composite | Omega (total) | Omega (hierarchical) | Omega (group)
----------------------------------------------------------------
g         |          0.97 |                 0.46 |          0.48
F1*       |          0.96 |                 0.40 |          0.56
F2*       |          1.00 |                 0.37 |          0.63

[34m# Variances[39m

Composite | Total (%) | General Factor (%) | Group Factor (%)
-------------------------------------------------------------
g         |     97.15 |              46.10 |            48.39
F1*       |     95.91 |              39.92 |            55.99
F2*       |     99.52 |              36.61 |            62.91
> parameters::model_parameters(result)
[34m# Rotated loadings from Omega (oblimin-rotation)[39m

Variable |    g |      F1* |   F2* |   h2 |       u2 |   p2 | Complexity
------------------------------------------------------------------------
mpg-     | 0.59 |     0.70 |  0.07 | 0.85 |     0.15 | 0.41 |       1.96
cyl      | 0.67 |     0.65 |  0.22 | 0.92 |     0.08 | 0.48 |       2.22
disp     | 0.61 |     0.73 |  0.07 | 0.91 |     0.09 | 0.41 |       1.96
hp       | 0.66 |     0.47 |  0.40 | 0.82 |     0.18 | 0.53 |       2.52
drat-    | 0.37 |     0.67 | -0.17 | 0.61 |     0.39 | 0.23 |       1.73
wt       | 0.49 |     0.79 | -0.15 | 0.90 |     0.10 | 0.27 |       1.75
qsec-    | 0.61 | 2.64e-03 |  0.79 | 1.00 | 4.75e-03 | 0.37 |       1.87
> ## End(Don't show)
> 
> 
> 
> cleanEx()
> nameEx("item_reliability")
> ### * item_reliability
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: item_reliability
> ### Title: Reliability Test for Items or Scales
> ### Aliases: item_reliability
> 
> ### ** Examples
> 
> data(mtcars)
> x <- mtcars[, c("cyl", "gear", "carb", "hp")]
> item_reliability(x)
Some of the values are negative. Maybe affected items need to be
  reverse-coded, e.g. using `datawizard::reverse()`.
[34m# Item Reliability[39m

Item | Alpha if deleted | Total Correlation | Discrimination
------------------------------------------------------------
cyl  |             0.05 |              0.83 |           0.83
gear |             0.11 |             -0.12 |          -0.13
carb |             0.06 |              0.76 |           0.75
hp   |             0.41 |              1.00 |           0.88
[33m
Mean inter-item-correlation = 0.294  Cronbach's alpha = 0.095[39m> 
> 
> 
> cleanEx()
> nameEx("item_split_half")
> ### * item_split_half
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: item_split_half
> ### Title: Split-Half Reliability
> ### Aliases: item_split_half
> 
> ### ** Examples
> 
> data(mtcars)
> x <- mtcars[, c("cyl", "gear", "carb", "hp")]
> item_split_half(x)
$splithalf
[1] 0.9070215

$spearmanbrown
[1] 0.9512441

> 
> 
> 
> cleanEx()
> nameEx("looic")
> ### * looic
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: looic
> ### Title: LOO-related Indices for Bayesian regressions.
> ### Aliases: looic
> 
> ### ** Examples
> 
> ## Don't show: 
> if (require("rstanarm")) withAutoprint({ # examplesIf
+ ## End(Don't show)
+ ## Don't show: 
+ }) # examplesIf
Loading required package: rstanarm
Loading required package: Rcpp
This is rstanarm version 2.32.2
- See https://mc-stan.org/rstanarm/articles/priors for changes to default priors!
- Default priors may change, so it's safest to specify priors, even if equivalent to the defaults.
- For execution on a local, multicore CPU with excess RAM we recommend calling
  options(mc.cores = parallel::detectCores())
> ## End(Don't show)
> 
> 
> 
> cleanEx()

detaching â€˜package:rstanarmâ€™, â€˜package:Rcppâ€™

> nameEx("model_performance")
> ### * model_performance
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: model_performance
> ### Title: Model Performance
> ### Aliases: model_performance performance
> 
> ### ** Examples
> 
> model <- lm(mpg ~ wt + cyl, data = mtcars)
> model_performance(model)
[34m# Indices of model performance[39m

AIC   |  AICc |   BIC |    R2 | R2 (adj.) |  RMSE | Sigma
---------------------------------------------------------
156.0 | 157.5 | 161.9 | 0.830 |     0.819 | 2.444 | 2.568
> 
> model <- glm(vs ~ wt + mpg, data = mtcars, family = "binomial")
> model_performance(model)
[34m# Indices of model performance[39m

AIC  | AICc |  BIC | Tjur's R2 |  RMSE | Sigma | Log_loss | Score_log
---------------------------------------------------------------------
31.3 | 32.2 | 35.7 |     0.478 | 0.359 |     1 |    0.395 |   -14.903

AIC  | Score_spherical |   PCP
------------------------------
31.3 |           0.095 | 0.743
> 
> 
> 
> cleanEx()
> nameEx("model_performance.fa")
> ### * model_performance.fa
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: model_performance.fa
> ### Title: Performance of FA / PCA models
> ### Aliases: model_performance.fa
> 
> ### ** Examples
> 
> ## Don't show: 
> if (all(insight::check_if_installed(c("psych", "GPArotation", "psychTools"), quietly = TRUE))) withAutoprint({ # examplesIf
+ ## End(Don't show)
+ out <- psych::fa(psychTools::bfi[, 1:25], 5)
+ model_performance(out)
+ 
+ out <- item_omega(mtcars, n = 3)
+ model_performance(out)
+ ## Don't show: 
+ }) # examplesIf
> out <- psych::fa(psychTools::bfi[, 1:25], 5)
> model_performance(out)
[34m# Indices of model performance[39m

Chi2(185) | p (Chi2) |  RMSR | RMSR_corrected |   TLI | RMSEA |   RMSEA 90% CI |   BIC
--------------------------------------------------------------------------------------
1808.943  |   < .001 | 0.029 |          0.037 | 0.867 | 0.056 | [0.054, 0.058] | 340.5
> out <- item_omega(mtcars, n = 3)
> model_performance(out)
[34m# Indices of model performance[39m

Model             |    Chi2 | df | p (Chi2) |  RMSR | RMSR_corrected |   TLI
----------------------------------------------------------------------------
3-factor solution |  31.796 | 25 |   0.164  | 0.011 |          0.016 |      
g-model           | 264.781 | 44 |   < .001 | 0.278 |          0.311 | 0.195

Model             | RMSEA |   RMSEA 90% CI |   BIC |    R2 | Correlation
------------------------------------------------------------------------
3-factor solution | 0.087 | [0.000, 0.181] | -54.8 |       |            
g-model           | 0.395 | [0.356, 0.450] | 112.3 | 0.886 |       0.941
[33m
Compare the model fit of the 3-factor solution with the g-only model.
  If the g-model has smaller RMSR and RMSEA then your items are more
  likely to describe a single unidimensional construct. If the 3-factor
  model has smaller RMSR and RMSEA then your construct is more likely to
  be made up of 3 sub-constructs.[39m> ## End(Don't show)
> 
> 
> 
> cleanEx()
> nameEx("model_performance.kmeans")
> ### * model_performance.kmeans
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: model_performance.kmeans
> ### Title: Model summary for k-means clustering
> ### Aliases: model_performance.kmeans
> 
> ### ** Examples
> 
> # a 2-dimensional example
> x <- rbind(
+   matrix(rnorm(100, sd = 0.3), ncol = 2),
+   matrix(rnorm(100, mean = 1, sd = 0.3), ncol = 2)
+ )
> colnames(x) <- c("x", "y")
> model <- kmeans(x, 2)
> model_performance(model)
[34m# Indices of model performance[39m

Sum_Squares_Total | Sum_Squares_Within | Sum_Squares_Between | Iterations
-------------------------------------------------------------------------
60.991            |             14.918 |              46.073 |          1
> 
> 
> 
> cleanEx()
> nameEx("model_performance.lavaan")
> ### * model_performance.lavaan
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: model_performance.lavaan
> ### Title: Performance of lavaan SEM / CFA Models
> ### Aliases: model_performance.lavaan
> 
> ### ** Examples
> 
> ## Don't show: 
> if (require("lavaan")) withAutoprint({ # examplesIf
+ ## End(Don't show)
+ # Confirmatory Factor Analysis (CFA) ---------
+ data(HolzingerSwineford1939, package = "lavaan")
+ structure <- " visual  =~ x1 + x2 + x3
+                textual =~ x4 + x5 + x6
+                speed   =~ x7 + x8 + x9 "
+ model <- lavaan::cfa(structure, data = HolzingerSwineford1939)
+ model_performance(model)
+ ## Don't show: 
+ }) # examplesIf
Loading required package: lavaan
This is lavaan 0.6-21
lavaan is FREE software! Please report any bugs.
> data(HolzingerSwineford1939, package = "lavaan")
> structure <- " visual  =~ x1 + x2 + x3\n               textual =~ x4 + x5 + x6\n               speed   =~ x7 + x8 + x9 "
> model <- lavaan::cfa(structure, data = HolzingerSwineford1939)
> model_performance(model)
[34m# Indices of model performance[39m

Chi2(24) | p (Chi2) | Baseline(36) | p (Baseline) |   GFI |  AGFI |   NFI
-------------------------------------------------------------------------
85.306   |   < .001 |      918.852 |       < .001 | 0.943 | 0.894 | 0.907

Chi2(24) |  NNFI |   CFI | RMSEA |      RMSEA  CI | p (RMSEA) |   RMR |  SRMR
-----------------------------------------------------------------------------
85.306   | 0.896 | 0.931 | 0.092 | [0.071, 0.114] |    < .001 | 0.082 | 0.065

Chi2(24) |   RFI |  PNFI |   IFI |   RNI | Loglikelihood |    AIC |    BIC | BIC_adjusted
-----------------------------------------------------------------------------------------
85.306   | 0.861 | 0.605 | 0.931 | 0.931 |     -3737.745 | 7517.5 | 7595.3 |     7528.739
> ## End(Don't show)
> 
> 
> 
> cleanEx()

detaching â€˜package:lavaanâ€™

> nameEx("model_performance.lm")
> ### * model_performance.lm
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: model_performance.lm
> ### Title: Performance of Regression Models
> ### Aliases: model_performance.lm
> 
> ### ** Examples
> 
> model <- lm(mpg ~ wt + cyl, data = mtcars)
> model_performance(model)
[34m# Indices of model performance[39m

AIC   |  AICc |   BIC |    R2 | R2 (adj.) |  RMSE | Sigma
---------------------------------------------------------
156.0 | 157.5 | 161.9 | 0.830 |     0.819 | 2.444 | 2.568
> 
> model <- glm(vs ~ wt + mpg, data = mtcars, family = "binomial")
> model_performance(model)
[34m# Indices of model performance[39m

AIC  | AICc |  BIC | Tjur's R2 |  RMSE | Sigma | Log_loss | Score_log
---------------------------------------------------------------------
31.3 | 32.2 | 35.7 |     0.478 | 0.359 |     1 |    0.395 |   -14.903

AIC  | Score_spherical |   PCP
------------------------------
31.3 |           0.095 | 0.743
> 
> 
> 
> cleanEx()
> nameEx("model_performance.merMod")
> ### * model_performance.merMod
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: model_performance.merMod
> ### Title: Performance of Mixed Models
> ### Aliases: model_performance.merMod
> 
> ### ** Examples
> 
> ## Don't show: 
> if (require("lme4")) withAutoprint({ # examplesIf
+ ## End(Don't show)
+ model <- lme4::lmer(Petal.Length ~ Sepal.Length + (1 | Species), data = iris)
+ model_performance(model)
+ ## Don't show: 
+ }) # examplesIf
Loading required package: lme4
Loading required package: Matrix
> model <- lme4::lmer(Petal.Length ~ Sepal.Length + (1 | Species), data = iris)
> model_performance(model)
[34m# Indices of model performance[39m

AIC  | AICc |  BIC | R2 (cond.) | R2 (marg.) |   ICC |  RMSE | Sigma
--------------------------------------------------------------------
77.3 | 77.6 | 89.4 |      0.972 |      0.096 | 0.969 | 0.279 | 0.283
> ## End(Don't show)
> 
> 
> 
> cleanEx()

detaching â€˜package:lme4â€™, â€˜package:Matrixâ€™

> nameEx("model_performance.rma")
> ### * model_performance.rma
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: model_performance.rma
> ### Title: Performance of Meta-Analysis Models
> ### Aliases: model_performance.rma
> 
> ### ** Examples
> 
> ## Don't show: 
> if (require("metafor") && require("metadat")) withAutoprint({ # examplesIf
+ ## End(Don't show)
+ data(dat.bcg, package = "metadat")
+ dat <- metafor::escalc(
+   measure = "RR",
+   ai = tpos,
+   bi = tneg,
+   ci = cpos,
+   di = cneg,
+   data = dat.bcg
+ )
+ model <- metafor::rma(yi, vi, data = dat, method = "REML")
+ model_performance(model)
+ ## Don't show: 
+ }) # examplesIf
Loading required package: metafor
Loading required package: Matrix
Loading required package: metadat
Loading required package: numDeriv

Loading the 'metafor' package (version 4.8-0). For an
introduction to the package please type: help(metafor)

> data(dat.bcg, package = "metadat")
> dat <- metafor::escalc(measure = "RR", ai = tpos, bi = tneg, ci = cpos, 
+     di = cneg, data = dat.bcg)
> model <- metafor::rma(yi, vi, data = dat, method = "REML")
> model_performance(model)
[34m# Indices of model performance[39m

AIC  |  BIC |    I2 |     H2 |  TAU2 | CochransQ | p (CochransQ) | df | Omnibus | p (Omnibus)
---------------------------------------------------------------------------------------------
29.4 | 30.5 | 0.922 | 12.856 | 0.313 |   152.233 |        < .001 | 12 |  15.796 |      < .001
> ## End(Don't show)
> 
> 
> 
> cleanEx()

detaching â€˜package:metaforâ€™, â€˜package:numDerivâ€™, â€˜package:metadatâ€™,
  â€˜package:Matrixâ€™

> nameEx("model_performance.stanreg")
> ### * model_performance.stanreg
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: model_performance.stanreg
> ### Title: Performance of Bayesian Models
> ### Aliases: model_performance.stanreg model_performance.BFBayesFactor
> 
> ### ** Examples
> 
> ## Don't show: 
> if (require("rstanarm") && require("rstantools")) withAutoprint({ # examplesIf
+ ## End(Don't show)
+ ## Don't show: 
+ }) # examplesIf
Loading required package: rstanarm
Loading required package: Rcpp
This is rstanarm version 2.32.2
- See https://mc-stan.org/rstanarm/articles/priors for changes to default priors!
- Default priors may change, so it's safest to specify priors, even if equivalent to the defaults.
- For execution on a local, multicore CPU with excess RAM we recommend calling
  options(mc.cores = parallel::detectCores())
Loading required package: rstantools
This is rstantools version 2.6.0
> ## End(Don't show)
> 
> 
> 
> cleanEx()

detaching â€˜package:rstantoolsâ€™, â€˜package:rstanarmâ€™, â€˜package:Rcppâ€™

> nameEx("performance_accuracy")
> ### * performance_accuracy
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: performance_accuracy
> ### Title: Accuracy of predictions from model fit
> ### Aliases: performance_accuracy
> 
> ### ** Examples
> 
> model <- lm(mpg ~ wt + cyl, data = mtcars)
> performance_accuracy(model)
[34m# Accuracy of Model Predictions

[39mAccuracy (95% CI): 89.40% [83.83%, 97.00%]
Method: Correlation between observed and predicted
> 
> model <- glm(vs ~ wt + mpg, data = mtcars, family = "binomial")
> performance_accuracy(model)
[34m# Accuracy of Model Predictions

[39mAccuracy (95% CI): 91.67% [69.17%, 100.00%]
Method: Area under Curve
> 
> 
> 
> cleanEx()
> nameEx("performance_aicc")
> ### * performance_aicc
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: performance_aicc
> ### Title: Compute the AIC or second-order AIC
> ### Aliases: performance_aicc performance_aic performance_aic.default
> ###   performance_aic.lmerMod
> 
> ### ** Examples
> 
> m <- lm(mpg ~ wt + cyl + gear + disp, data = mtcars)
> AIC(m)
[1] 159.1051
> performance_aicc(m)
[1] 162.4651
> 
> # correct AIC for models with transformed response variable
> data("mtcars")
> mtcars$mpg <- floor(mtcars$mpg)
> model <- lm(log(mpg) ~ factor(cyl), mtcars)
> 
> # wrong AIC, not corrected for log-transformation
> AIC(model)
[1] -19.67061
> 
> # performance_aic() correctly detects transformed response and
> # returns corrected AIC
> performance_aic(model)
[1] 168.2152
> 
> ## Not run: 
> ##D # there are a few exceptions where the corrected log-likelihood values
> ##D # cannot be returned. The following exampe gives a warning.
> ##D model <- lm(1 / mpg ~ factor(cyl), mtcars)
> ##D performance_aic(model)
> ## End(Not run)
> 
> 
> 
> cleanEx()
> nameEx("performance_cv")
> ### * performance_cv
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: performance_cv
> ### Title: Cross-validated model performance
> ### Aliases: performance_cv
> 
> ### ** Examples
> 
> model <- lm(mpg ~ wt + cyl, data = mtcars)
> performance_cv(model)
[34m# Cross-validation performance (30% holdout method)[39m

MSE | RMSE |   R2
-----------------
5.5 |  2.4 | 0.83
> 
> 
> 
> 
> cleanEx()
> nameEx("performance_hosmer")
> ### * performance_hosmer
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: performance_hosmer
> ### Title: Hosmer-Lemeshow goodness-of-fit test
> ### Aliases: performance_hosmer
> 
> ### ** Examples
> 
> model <- glm(vs ~ wt + mpg, data = mtcars, family = "binomial")
> performance_hosmer(model)
[34m# Hosmer-Lemeshow Goodness-of-Fit Test

[39m  Chi-squared: 5.137
           df: 8    
      p-value: 0.743

Summary: model seems to fit well.
> 
> 
> 
> cleanEx()
> nameEx("performance_logloss")
> ### * performance_logloss
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: performance_logloss
> ### Title: Log Loss
> ### Aliases: performance_logloss
> 
> ### ** Examples
> 
> data(mtcars)
> m <- glm(formula = vs ~ hp + wt, family = binomial, data = mtcars)
> performance_logloss(m)
[1] 0.2517054
> 
> 
> 
> cleanEx()
> nameEx("performance_mae")
> ### * performance_mae
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: performance_mae
> ### Title: Mean Absolute Error of Models
> ### Aliases: performance_mae mae
> 
> ### ** Examples
> 
> data(mtcars)
> m <- lm(mpg ~ hp + gear, data = mtcars)
> performance_mae(m)
[1] 2.545822
> 
> 
> 
> cleanEx()
> nameEx("performance_mse")
> ### * performance_mse
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: performance_mse
> ### Title: Mean Square Error of Linear Models
> ### Aliases: performance_mse mse
> 
> ### ** Examples
> 
> data(mtcars)
> m <- lm(mpg ~ hp + gear, data = mtcars)
> performance_mse(m)
[1] 8.752858
> 
> 
> 
> cleanEx()
> nameEx("performance_pcp")
> ### * performance_pcp
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: performance_pcp
> ### Title: Percentage of Correct Predictions
> ### Aliases: performance_pcp
> 
> ### ** Examples
> 
> data(mtcars)
> m <- glm(formula = vs ~ hp + wt, family = binomial, data = mtcars)
> performance_pcp(m)
[34m# Percentage of Correct Predictions from Logistic Regression Model

[39m  Full model: 83.75% [70.96% - 96.53%]
  Null model: 50.78% [33.46% - 68.10%]
[34m
# Likelihood-Ratio-Test

[39m  Chi-squared: 27.751
  df:  2.000
  p-value:  0.000

> performance_pcp(m, method = "Gelman-Hill")
[34m# Percentage of Correct Predictions from Logistic Regression Model

[39m  Full model: 87.50% [76.04% - 98.96%]
  Null model: 56.25% [39.06% - 73.44%]
[34m
# Likelihood-Ratio-Test

[39m  Chi-squared: 27.751
  df:  2.000
  p-value:  0.000

> 
> 
> 
> cleanEx()
> nameEx("performance_reliability")
> ### * performance_reliability
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: performance_reliability
> ### Title: Random Effects Reliability
> ### Aliases: performance_reliability performance_dvour
> 
> ### ** Examples
> 
> ## Don't show: 
> if (all(insight::check_if_installed(c("lme4", "glmmTMB"), quietly = TRUE))) withAutoprint({ # examplesIf
+ ## End(Don't show)
+ url <- "https://raw.githubusercontent.com/easystats/circus/refs/heads/main/data/illusiongame.csv"
+ df <- read.csv(url)
+ 
+ m <- lme4::lmer(RT ~ (1 | Participant), data = df)
+ performance_reliability(m)
+ performance_dvour(m)
+ 
+ m <- glmmTMB::glmmTMB(RT ~ (1 | Participant), data = df)
+ performance_reliability(m)
+ performance_dvour(m)
+ 
+ m <- lme4::lmer(RT ~ (1 | Participant) + (1 | Trial), data = df)
+ performance_reliability(m)
+ performance_dvour(m)
+ 
+ m <- glmmTMB::glmmTMB(RT ~ (1 | Participant) + (1 | Trial), data = df)
+ performance_reliability(m)
+ performance_dvour(m)
+ 
+ ## Don't show: 
+ }) # examplesIf
> url <- "https://raw.githubusercontent.com/easystats/circus/refs/heads/main/data/illusiongame.csv"
> df <- read.csv(url)
> m <- lme4::lmer(RT ~ (1 | Participant), data = df)
> performance_reliability(m)
        Group   Parameter Reliability
1 Participant (Intercept)    0.155448
> performance_dvour(m)
        Group   Parameter    D_vour
1 Participant (Intercept) 0.9781019
> m <- glmmTMB::glmmTMB(RT ~ (1 | Participant), data = df)
> performance_reliability(m)
        Group   Parameter Reliability
1 Participant (Intercept)   0.1528589
> performance_dvour(m)
        Group   Parameter    D_vour
1 Participant (Intercept) 0.9603575
> m <- lme4::lmer(RT ~ (1 | Participant) + (1 | Trial), data = df)
> performance_reliability(m)
        Group   Parameter Reliability
1       Trial (Intercept) 0.005897166
2 Participant (Intercept) 0.156391605
> performance_dvour(m)
        Group   Parameter    D_vour
1 Participant (Intercept) 0.9777044
2       Trial (Intercept) 0.5664226
> m <- glmmTMB::glmmTMB(RT ~ (1 | Participant) + (1 | Trial), data = df)
> performance_reliability(m)
        Group   Parameter Reliability
1 Participant (Intercept)  0.15386342
2       Trial (Intercept)  0.00588784
> performance_dvour(m)
Cannot extract confidence intervals for random variance parameters from
  models with more than one grouping factor.
        Group   Parameter    D_vour
1 Participant (Intercept) 0.9604671
2       Trial (Intercept) 0.5602238
> ## End(Don't show)
> 
> 
> 
> cleanEx()
> nameEx("performance_rmse")
> ### * performance_rmse
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: performance_rmse
> ### Title: Root Mean Squared Error
> ### Aliases: performance_rmse rmse
> 
> ### ** Examples
> 
> ## Don't show: 
> if (require("nlme")) withAutoprint({ # examplesIf
+ ## End(Don't show)
+ data(Orthodont, package = "nlme")
+ m <- nlme::lme(distance ~ age, data = Orthodont)
+ 
+ # RMSE
+ performance_rmse(m, normalized = FALSE)
+ 
+ # normalized RMSE
+ performance_rmse(m, normalized = TRUE)
+ ## Don't show: 
+ }) # examplesIf
Loading required package: nlme
> data(Orthodont, package = "nlme")
> m <- nlme::lme(distance ~ age, data = Orthodont)
> performance_rmse(m, normalized = FALSE)
[1] 1.086327
> performance_rmse(m, normalized = TRUE)
[1] 0.07242178
> ## End(Don't show)
> 
> 
> 
> cleanEx()

detaching â€˜package:nlmeâ€™

> nameEx("performance_roc")
> ### * performance_roc
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: performance_roc
> ### Title: Simple ROC curve
> ### Aliases: performance_roc
> 
> ### ** Examples
> 
> library(bayestestR)
> data(iris)
> 
> set.seed(123)
> iris$y <- rbinom(nrow(iris), size = 1, .3)
> folds <- sample(nrow(iris), size = nrow(iris) / 8, replace = FALSE)
> test_data <- iris[folds, ]
> train_data <- iris[-folds, ]
> 
> model <- glm(y ~ Sepal.Length + Sepal.Width, data = train_data, family = "binomial")
> as.data.frame(performance_roc(model, new_data = test_data))
   Sensitivity Specificity   Model
1    0.0000000  0.00000000 Model 1
2    0.1428571  0.00000000 Model 1
3    0.1428571  0.09090909 Model 1
4    0.1428571  0.18181818 Model 1
5    0.1428571  0.27272727 Model 1
6    0.1428571  0.36363636 Model 1
7    0.2857143  0.36363636 Model 1
8    0.2857143  0.45454545 Model 1
9    0.2857143  0.54545455 Model 1
10   0.2857143  0.63636364 Model 1
11   0.2857143  0.72727273 Model 1
12   0.4285714  0.72727273 Model 1
13   0.5714286  0.72727273 Model 1
14   0.5714286  0.81818182 Model 1
15   0.7142857  0.81818182 Model 1
16   0.8571429  0.81818182 Model 1
17   0.8571429  0.90909091 Model 1
18   1.0000000  0.90909091 Model 1
19   1.0000000  1.00000000 Model 1
20   1.0000000  1.00000000 Model 1
> as.numeric(performance_roc(model))
[1] 0.540825
> 
> roc <- performance_roc(model, new_data = test_data)
> area_under_curve(roc$Specificity, roc$Sensitivity)
[1] 0.3766234
> 
> if (interactive()) {
+   m1 <- glm(y ~ Sepal.Length + Sepal.Width, data = iris, family = "binomial")
+   m2 <- glm(y ~ Sepal.Length + Petal.Width, data = iris, family = "binomial")
+   m3 <- glm(y ~ Sepal.Length + Species, data = iris, family = "binomial")
+   performance_roc(m1, m2, m3)
+ 
+   # if you have `see` package installed, you can also plot comparison of
+   # ROC curves for different models
+   if (require("see")) plot(performance_roc(m1, m2, m3))
+ }
> 
> 
> 
> cleanEx()

detaching â€˜package:bayestestRâ€™

> nameEx("performance_rse")
> ### * performance_rse
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: performance_rse
> ### Title: Residual Standard Error for Linear Models
> ### Aliases: performance_rse
> 
> ### ** Examples
> 
> data(mtcars)
> m <- lm(mpg ~ hp + gear, data = mtcars)
> performance_rse(m)
[1] 3.107785
> 
> 
> 
> cleanEx()
> nameEx("performance_score")
> ### * performance_score
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: performance_score
> ### Title: Proper Scoring Rules
> ### Aliases: performance_score
> 
> ### ** Examples
> 
> ## Don't show: 
> if (require("glmmTMB")) withAutoprint({ # examplesIf
+ ## End(Don't show)
+ ## Dobson (1990) Page 93: Randomized Controlled Trial :
+ counts <- c(18, 17, 15, 20, 10, 20, 25, 13, 12)
+ outcome <- gl(3, 1, 9)
+ treatment <- gl(3, 3)
+ model <- glm(counts ~ outcome + treatment, family = poisson())
+ 
+ performance_score(model)
+ ## Don't show: 
+ }) # examplesIf
Loading required package: glmmTMB
> counts <- c(18, 17, 15, 20, 10, 20, 25, 13, 12)
> outcome <- gl(3, 1, 9)
> treatment <- gl(3, 3)
> model <- glm(counts ~ outcome + treatment, family = poisson())
> performance_score(model)
[34m# Proper Scoring Rules

[39mlogarithmic: -2.5979
  quadratic:  0.2095
  spherical:  0.3238
> ## End(Don't show)
> 
> 
> 
> cleanEx()

detaching â€˜package:glmmTMBâ€™

> nameEx("r2")
> ### * r2
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: r2
> ### Title: Compute the model's R2
> ### Aliases: r2 r2.default r2.mlm r2.merMod
> 
> ### ** Examples
> 
> ## Don't show: 
> if (require("lme4")) withAutoprint({ # examplesIf
+ ## End(Don't show)
+ # Pseudo r-quared for GLM
+ model <- glm(vs ~ wt + mpg, data = mtcars, family = "binomial")
+ r2(model)
+ 
+ # r-squared including confidence intervals
+ model <- lm(mpg ~ wt + hp, data = mtcars)
+ r2(model, ci = 0.95)
+ 
+ model <- lme4::lmer(Sepal.Length ~ Petal.Length + (1 | Species), data = iris)
+ r2(model)
+ ## Don't show: 
+ }) # examplesIf
Loading required package: lme4
Loading required package: Matrix
> model <- glm(vs ~ wt + mpg, data = mtcars, family = "binomial")
> r2(model)
[34m# R2 for Logistic Regression
[39m  Tjur's R2: 0.478
> model <- lm(mpg ~ wt + hp, data = mtcars)
> r2(model, ci = 0.95)
       R2: 0.827 [0.654, 0.906]
  adj. R2: 0.815 [0.632, 0.899]
> model <- lme4::lmer(Sepal.Length ~ Petal.Length + (1 | Species), data = iris)
> r2(model)
[34m# R2 for Mixed Models

[39m  Conditional R2: 0.969
     Marginal R2: 0.658
> ## End(Don't show)
> 
> 
> 
> cleanEx()

detaching â€˜package:lme4â€™, â€˜package:Matrixâ€™

> nameEx("r2_bayes")
> ### * r2_bayes
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: r2_bayes
> ### Title: Bayesian R2
> ### Aliases: r2_bayes r2_posterior r2_posterior.brmsfit
> ###   r2_posterior.stanreg r2_posterior.BFBayesFactor
> 
> ### ** Examples
> 
> ## Don't show: 
> if (require("rstanarm") && require("rstantools") && require("brms") && require("RcppEigen")) withAutoprint({ # examplesIf
+ ## End(Don't show)
+ library(performance)
+ 
+ ## Don't show: 
+ }) # examplesIf
Loading required package: rstanarm
Loading required package: Rcpp
This is rstanarm version 2.32.2
- See https://mc-stan.org/rstanarm/articles/priors for changes to default priors!
- Default priors may change, so it's safest to specify priors, even if equivalent to the defaults.
- For execution on a local, multicore CPU with excess RAM we recommend calling
  options(mc.cores = parallel::detectCores())
Loading required package: rstantools
This is rstantools version 2.6.0
Loading required package: brms
Warning in library(package, lib.loc = lib.loc, character.only = TRUE, logical.return = TRUE,  :
  there is no package called â€˜brmsâ€™
> ## End(Don't show)
> 
> 
> 
> cleanEx()

detaching â€˜package:rstantoolsâ€™, â€˜package:rstanarmâ€™, â€˜package:Rcppâ€™

> nameEx("r2_coxsnell")
> ### * r2_coxsnell
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: r2_coxsnell
> ### Title: Cox & Snell's R2
> ### Aliases: r2_coxsnell
> 
> ### ** Examples
> 
> model <- glm(vs ~ wt + mpg, data = mtcars, family = "binomial")
> r2_coxsnell(model)
Cox & Snell's R2 
       0.4401407 
> 
> 
> 
> 
> cleanEx()
> nameEx("r2_efron")
> ### * r2_efron
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: r2_efron
> ### Title: Efron's R2
> ### Aliases: r2_efron
> 
> ### ** Examples
> 
> ## Dobson (1990) Page 93: Randomized Controlled Trial:
> counts <- c(18, 17, 15, 20, 10, 20, 25, 13, 12) #
> outcome <- gl(3, 1, 9)
> treatment <- gl(3, 3)
> model <- glm(counts ~ outcome + treatment, family = poisson())
> 
> r2_efron(model)
[1] 0.5265152
> 
> 
> 
> cleanEx()
> nameEx("r2_ferrari")
> ### * r2_ferrari
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: r2_ferrari
> ### Title: Ferrari's and Cribari-Neto's R2
> ### Aliases: r2_ferrari r2_ferrari.default
> 
> ### ** Examples
> 
> ## Don't show: 
> if (require("betareg")) withAutoprint({ # examplesIf
+ ## End(Don't show)
+ data("GasolineYield", package = "betareg")
+ model <- betareg::betareg(yield ~ batch + temp, data = GasolineYield)
+ r2_ferrari(model)
+ ## Don't show: 
+ }) # examplesIf
Loading required package: betareg
> data("GasolineYield", package = "betareg")
> model <- betareg::betareg(yield ~ batch + temp, data = GasolineYield)
> r2_ferrari(model)
[34m# R2 for Generalized Linear Regression
[39m  Ferrari's R2: 0.962
> ## End(Don't show)
> 
> 
> 
> cleanEx()

detaching â€˜package:betaregâ€™

> nameEx("r2_kullback")
> ### * r2_kullback
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: r2_kullback
> ### Title: Kullback-Leibler R2
> ### Aliases: r2_kullback r2_kullback.glm
> 
> ### ** Examples
> 
> model <- glm(vs ~ wt + mpg, data = mtcars, family = "binomial")
> r2_kullback(model)
Kullback-Leibler R2 
          0.3834362 
> 
> 
> 
> cleanEx()
> nameEx("r2_loo")
> ### * r2_loo
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: r2_loo
> ### Title: LOO-adjusted R2
> ### Aliases: r2_loo r2_loo_posterior r2_loo_posterior.brmsfit
> ###   r2_loo_posterior.stanreg
> 
> ### ** Examples
> 
> ## Don't show: 
> if (require("rstanarm") && require("rstantools")) withAutoprint({ # examplesIf
+ ## End(Don't show)
+ model <- suppressWarnings(rstanarm::stan_glm(
+   mpg ~ wt + cyl,
+   data = mtcars,
+   chains = 1,
+   iter = 500,
+   refresh = 0,
+   show_messages = FALSE
+ ))
+ r2_loo(model)
+ ## Don't show: 
+ }) # examplesIf
Loading required package: rstanarm
Loading required package: Rcpp
This is rstanarm version 2.32.2
- See https://mc-stan.org/rstanarm/articles/priors for changes to default priors!
- Default priors may change, so it's safest to specify priors, even if equivalent to the defaults.
- For execution on a local, multicore CPU with excess RAM we recommend calling
  options(mc.cores = parallel::detectCores())
Loading required package: rstantools
This is rstantools version 2.6.0
> model <- suppressWarnings(rstanarm::stan_glm(mpg ~ wt + cyl, data = mtcars, 
+     chains = 1, iter = 500, refresh = 0, show_messages = FALSE))
> r2_loo(model)
Warning: Some Pareto k diagnostic values are too high. See help('pareto-k-diagnostic') for details.

[34m# LOO-adjusted R2 with Compatibility Interval

[39m  Conditional R2: 0.802 (95% CI [0.706, 0.898])
> ## End(Don't show)
> 
> 
> 
> cleanEx()

detaching â€˜package:rstantoolsâ€™, â€˜package:rstanarmâ€™, â€˜package:Rcppâ€™

> nameEx("r2_mcfadden")
> ### * r2_mcfadden
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: r2_mcfadden
> ### Title: McFadden's R2
> ### Aliases: r2_mcfadden
> 
> ### ** Examples
> 
> if (require("mlogit")) {
+   data("Fishing", package = "mlogit")
+   Fish <- mlogit.data(Fishing, varying = c(2:9), shape = "wide", choice = "mode")
+ 
+   model <- mlogit(mode ~ price + catch, data = Fish)
+   r2_mcfadden(model)
+ }
Loading required package: mlogit
Loading required package: dfidx
McFadden's R2 
      0.17823 
> 
> 
> 
> cleanEx()

detaching â€˜package:mlogitâ€™, â€˜package:dfidxâ€™

> nameEx("r2_mckelvey")
> ### * r2_mckelvey
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: r2_mckelvey
> ### Title: McKelvey & Zavoinas R2
> ### Aliases: r2_mckelvey
> 
> ### ** Examples
> 
> ## Dobson (1990) Page 93: Randomized Controlled Trial:
> counts <- c(18, 17, 15, 20, 10, 20, 25, 13, 12) #
> outcome <- gl(3, 1, 9)
> treatment <- gl(3, 3)
> model <- glm(counts ~ outcome + treatment, family = poisson())
> 
> r2_mckelvey(model)
McKelvey's R2 
    0.3776292 
> 
> 
> 
> cleanEx()
> nameEx("r2_mlm")
> ### * r2_mlm
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: r2_mlm
> ### Title: Multivariate R2
> ### Aliases: r2_mlm
> 
> ### ** Examples
> 
> model <- lm(cbind(qsec, drat) ~ wt + mpg + cyl, data = mtcars)
> r2_mlm(model)
 Symmetric Rxy Asymmetric Pxy 
     0.8573111      0.5517522 
> 
> model_swap <- lm(cbind(wt, mpg, cyl) ~ qsec + drat, data = mtcars)
> r2_mlm(model_swap)
 Symmetric Rxy Asymmetric Pxy 
     0.8573111      0.3678348 
> 
> 
> 
> 
> cleanEx()
> nameEx("r2_nagelkerke")
> ### * r2_nagelkerke
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: r2_nagelkerke
> ### Title: Nagelkerke's R2
> ### Aliases: r2_nagelkerke
> 
> ### ** Examples
> 
> model <- glm(vs ~ wt + mpg, data = mtcars, family = "binomial")
> r2_nagelkerke(model)
Nagelkerke's R2 
      0.5899593 
> 
> 
> 
> cleanEx()
> nameEx("r2_nakagawa")
> ### * r2_nakagawa
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: r2_nakagawa
> ### Title: Nakagawa's R2 for mixed models
> ### Aliases: r2_nakagawa
> 
> ### ** Examples
> 
> ## Don't show: 
> if (require("lme4")) withAutoprint({ # examplesIf
+ ## End(Don't show)
+ model <- lme4::lmer(Sepal.Length ~ Petal.Length + (1 | Species), data = iris)
+ r2_nakagawa(model)
+ r2_nakagawa(model, by_group = TRUE)
+ ## Don't show: 
+ }) # examplesIf
Loading required package: lme4
Loading required package: Matrix
> model <- lme4::lmer(Sepal.Length ~ Petal.Length + (1 | Species), data = iris)
> r2_nakagawa(model)
[34m# R2 for Mixed Models

[39m  Conditional R2: 0.969
     Marginal R2: 0.658
> r2_nakagawa(model, by_group = TRUE)
[34m# Explained Variance by Level

[39mLevel   |     R2
----------------
Level 1 |  0.569
Species | -0.853

> ## End(Don't show)
> 
> 
> 
> cleanEx()

detaching â€˜package:lme4â€™, â€˜package:Matrixâ€™

> nameEx("r2_somers")
> ### * r2_somers
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: r2_somers
> ### Title: Somers' Dxy rank correlation for binary outcomes
> ### Aliases: r2_somers
> 
> ### ** Examples
> 
> 
> 
> 
> 
> cleanEx()
> nameEx("r2_tjur")
> ### * r2_tjur
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: r2_tjur
> ### Title: Tjur's R2 - coefficient of determination (D)
> ### Aliases: r2_tjur
> 
> ### ** Examples
> 
> model <- glm(vs ~ wt + mpg, data = mtcars, family = "binomial")
> r2_tjur(model)
Tjur's R2 
0.4776926 
> 
> 
> 
> 
> cleanEx()
> nameEx("r2_xu")
> ### * r2_xu
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: r2_xu
> ### Title: Xu' R2 (Omega-squared)
> ### Aliases: r2_xu
> 
> ### ** Examples
> 
> model <- lm(Sepal.Length ~ Petal.Length + Species, data = iris)
> r2_xu(model)
  Xu's R2 
0.8367238 
> 
> 
> 
> cleanEx()
> nameEx("r2_zeroinflated")
> ### * r2_zeroinflated
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: r2_zeroinflated
> ### Title: R2 for models with zero-inflation
> ### Aliases: r2_zeroinflated
> 
> ### ** Examples
> 
> 
> 
> 
> cleanEx()
> nameEx("simulate_residuals")
> ### * simulate_residuals
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: simulate_residuals
> ### Title: Simulate randomized quantile residuals from a model
> ### Aliases: simulate_residuals residuals.performance_simres
> 
> ### ** Examples
> 
> ## Don't show: 
> if (require("DHARMa")) withAutoprint({ # examplesIf
+ ## End(Don't show)
+ m <- lm(mpg ~ wt + cyl + gear + disp, data = mtcars)
+ simulate_residuals(m)
+ 
+ # extract residuals
+ head(residuals(simulate_residuals(m)))
+ ## Don't show: 
+ }) # examplesIf
Loading required package: DHARMa
This is DHARMa 0.4.7. For overview type '?DHARMa'. For recent changes, type news(package = 'DHARMa')
> m <- lm(mpg ~ wt + cyl + gear + disp, data = mtcars)
> simulate_residuals(m)
Simulated residuals from a model of class `lm` based on 250 simulations.
  Use `check_residuals()` to check uniformity of residuals or
  `residuals()` to extract simulated residuals. It is recommended to refer
  to `?DHARMa::simulateResiudals` and `vignette("DHARMa")` for more
  information about different settings in particular situations or for
  particular models.
> head(residuals(simulate_residuals(m)))
[1] 0.356 0.448 0.096 0.568 0.668 0.204
> ## End(Don't show)
> 
> 
> 
> cleanEx()

detaching â€˜package:DHARMaâ€™

> nameEx("test_performance")
> ### * test_performance
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: test_bf
> ### Title: Test if models are different
> ### Aliases: test_bf test_bf.default test_likelihoodratio test_lrt
> ###   test_performance test_vuong test_wald
> 
> ### ** Examples
> 
> # Nested Models
> # -------------
> m1 <- lm(Sepal.Length ~ Petal.Width, data = iris)
> m2 <- lm(Sepal.Length ~ Petal.Width + Species, data = iris)
> m3 <- lm(Sepal.Length ~ Petal.Width * Species, data = iris)
> 
> test_performance(m1, m2, m3)
Name | Model |    BF |   Omega2 | p (Omega2) |   LR | p (LR)
------------------------------------------------------------
m1   |    lm |       |          |            |      |       
m2   |    lm | 0.007 | 9.54e-04 |      0.935 | 0.15 |  0.919
m3   |    lm | 0.037 |     0.02 |      0.081 | 3.41 |  0.099
Models were detected as nested (in terms of fixed parameters) and are compared in sequential order.
> 
> test_bf(m1, m2, m3)
[34mBayes Factors for Model Comparison[39m

     Model                       BF
[m2] Petal.Width + Species    0.007
[m3] Petal.Width * Species 2.64e-04

* Against Denominator: [36m[m1] Petal.Width[39m
*   Bayes Factor Type: [36mBIC approximation[39m> test_wald(m1, m2, m3) # Equivalent to anova(m1, m2, m3)
Name | Model |  df | df_diff |    F |     p
-------------------------------------------
m1   |    lm | 148 |         |      |      
m2   |    lm | 146 |       2 | 0.08 | 0.927
m3   |    lm | 144 |       2 | 1.66 | 0.195
Models were detected as nested (in terms of fixed parameters) and are compared in sequential order.
> 
> # Equivalent to lmtest::lrtest(m1, m2, m3)
> test_likelihoodratio(m1, m2, m3, estimator = "ML")
[34m# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)[39m

Name | Model | df | df_diff | Chi2 |     p
------------------------------------------
m1   |    lm |  3 |         |      |      
m2   |    lm |  5 |       2 | 0.15 | 0.926
m3   |    lm |  7 |       2 | 3.41 | 0.182
> 
> # Equivalent to anova(m1, m2, m3, test='LRT')
> test_likelihoodratio(m1, m2, m3, estimator = "OLS")
[34m# Likelihood-Ratio-Test (LRT) for Model Comparison (OLS-estimator)[39m

Name | Model | df | df_diff | Chi2 |     p
------------------------------------------
m1   |    lm |  3 |         |      |      
m2   |    lm |  5 |       2 | 0.15 | 0.927
m3   |    lm |  7 |       2 | 3.31 | 0.191
> 
> if (require("CompQuadForm")) {
+   test_vuong(m1, m2, m3) # nonnest2::vuongtest(m1, m2, nested=TRUE)
+ 
+   # Non-nested Models
+   # -----------------
+   m1 <- lm(Sepal.Length ~ Petal.Width, data = iris)
+   m2 <- lm(Sepal.Length ~ Petal.Length, data = iris)
+   m3 <- lm(Sepal.Length ~ Species, data = iris)
+ 
+   test_performance(m1, m2, m3)
+   test_bf(m1, m2, m3)
+   test_vuong(m1, m2, m3) # nonnest2::vuongtest(m1, m2)
+ }
Loading required package: CompQuadForm
Name | Model | Omega2 | p (Omega2) |    LR | p (LR)
---------------------------------------------------
m1   |    lm |        |            |       |       
m2   |    lm |   0.19 |     < .001 | -4.57 | < .001
m3   |    lm |   0.12 |     < .001 |  2.51 | 0.006 
Each model is compared to m1.
> 
> # Tweak the output
> # ----------------
> test_performance(m1, m2, m3, include_formula = TRUE)
Name |                           Model |      BF | Omega2 | p (Omega2) |    LR | p (LR)
---------------------------------------------------------------------------------------
m1   |  lm(Sepal.Length ~ Petal.Width) |         |        |            |       |       
m2   | lm(Sepal.Length ~ Petal.Length) |  > 1000 |   0.19 |     < .001 | -4.57 | < .001
m3   |      lm(Sepal.Length ~ Species) | < 0.001 |   0.12 |     < .001 |  2.51 | 0.006 
Each model is compared to m1.
> 
> 
> # SEM / CFA (lavaan objects)
> # --------------------------
> # Lavaan Models
> if (require("lavaan")) {
+   structure <- " visual  =~ x1 + x2 + x3
+                  textual =~ x4 + x5 + x6
+                  speed   =~ x7 + x8 + x9
+ 
+                   visual ~~ textual + speed "
+   m1 <- lavaan::cfa(structure, data = HolzingerSwineford1939)
+ 
+   structure <- " visual  =~ x1 + x2 + x3
+                  textual =~ x4 + x5 + x6
+                  speed   =~ x7 + x8 + x9
+ 
+                   visual ~~ 0 * textual + speed "
+   m2 <- lavaan::cfa(structure, data = HolzingerSwineford1939)
+ 
+   structure <- " visual  =~ x1 + x2 + x3
+                  textual =~ x4 + x5 + x6
+                  speed   =~ x7 + x8 + x9
+ 
+                   visual ~~ 0 * textual + 0 * speed "
+   m3 <- lavaan::cfa(structure, data = HolzingerSwineford1939)
+ 
+   test_likelihoodratio(m1, m2, m3)
+ 
+   # Different Model Types
+   # ---------------------
+   if (require("lme4") && require("mgcv")) {
+     m1 <- lm(Sepal.Length ~ Petal.Length + Species, data = iris)
+     m2 <- lmer(Sepal.Length ~ Petal.Length + (1 | Species), data = iris)
+     m3 <- gam(Sepal.Length ~ s(Petal.Length, by = Species) + Species, data = iris)
+ 
+     test_performance(m1, m2, m3)
+   }
+ }
Loading required package: lavaan
This is lavaan 0.6-21
lavaan is FREE software! Please report any bugs.
Loading required package: lme4
Loading required package: Matrix
Loading required package: mgcv
Loading required package: nlme

Attaching package: â€˜nlmeâ€™

The following object is masked from â€˜package:lme4â€™:

    lmList

This is mgcv 1.9-4. For overview type '?mgcv'.
Name |   Model |      BF
------------------------
m1   |      lm |        
m2   | lmerMod | < 0.001
m3   |     gam |   0.038
Each model is compared to m1.
> 
> 
> 
> 
> ### * <FOOTER>
> ###
> cleanEx()

detaching â€˜package:mgcvâ€™, â€˜package:nlmeâ€™, â€˜package:lme4â€™,
  â€˜package:Matrixâ€™, â€˜package:lavaanâ€™, â€˜package:CompQuadFormâ€™

> options(digits = 7L)
> base::cat("Time elapsed: ", proc.time() - base::get("ptime", pos = 'CheckExEnv'),"\n")
Time elapsed:  20.586 1.145 28.401 0.004 0.005 
> grDevices::dev.off()
null device 
          1 
> ###
> ### Local variables: ***
> ### mode: outline-minor ***
> ### outline-regexp: "\\(> \\)?### [*]+" ***
> ### End: ***
> quit('no')
