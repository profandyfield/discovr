---
title: "discovr: Bayes"
author: "Andy Field"
output:
  learnr::tutorial:
    progressive: true
    allow_skip: true
    theme: "united"
    highlight: "kate"
    css: ./css/discovr_style_future.css
runtime: shiny_prerendered
description: "Bayesian taster tutorial. This tutorial offers a taster of Bayesian statistics by showing how to conduct various analyses from other tutorials within a Bayesian framework (mainly using default priors). We also look at Bayes factors."
bibliography: [discovr_bayes.bib, packages.bib]
---

<html lang="en">

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE
)

#necessary to render tutorial correctly
library(learnr) 
library(htmltools)
#easystats
library(bayestestR)
library(insight)
library(parameters)
library(performance)
#tidyverse
library(dplyr)
library(ggplot2)
library(tibble)
#non tidyverse/easystats
library(rstanarm)
#students don't use
library(patchwork)

source("./www/discovr_helpers.R")


#Read dat files needed for the tutorial

album_tib <- discovr::album_sales

# get plot aesthetics
line_width <- 1
tol_palette <- discovr::tol_muted_pal()(8)
tol_blue <- tol_palette[5]
tol_bile <- tol_palette[7]
tol_rose <- tol_palette[1]
```


# discovr: Bayesian statistics

```{r, child = "intro.Rmd"}

```

## Packages

```{r, child = "packages.Rmd"}

```


## Data

```{r, child = "data.Rmd"}

```

## `r bmu()` General linear models [(D)]{.lbl}

To start with, we'll look back at the example from Chapter 8 [@fielddsr22026] that looks at predicting physical, downloaded and streamed album sales (outcome variable) from various predictor variables (we encountered this exam ple in `discovr_08`). The data file has 200 rows, each one representing a different album. There are also several columns, one of which contains the sales (in thousands) of each album in the week after release (`sales`) and one containing the amount (in thousands of pounds/dollars/euro/whatever currency you use) spent promoting the album before release (`adverts`). The other columns represent how many times songs from the album were played on a prominent national radio station in the week before release (`airplay`), and the 'look' of the band out of 10 (`image`). The data are in a tibble called [album_tib]{.alt}.

#### `r alien()` Alien coding challenge

Use the code box to view the data.

<div class="tip">
  `r cat_space()` **Hint**
  
  Remember to view an object in `r rproj()` execute its name.
</div>

```{r album_data, exercise = TRUE, exercise.lines = 2}

```

```{r album_data-solution}
album_tib
```

Note how the data are laid out: each variable is in a column and each row represents a different album. So, the first album had Â£10,260 spent advertising it, sold 330,000 copies (remember sales are in thousands), received 43 plays on radio the week before release, and was made by a band with a pretty sick image (10 out of 10!).

You can revisit `discovr_08` to look at descriptive statistics and scatterplots of the variables. The final model we fitted in `discovr_08` is described by:

$$
\begin{aligned}
Y_i & = b_0 + b_1X_{1i}+ b_2X_{2i} + \ldots + b_nX_{ni} + \varepsilon_i\\
\text{Sales}_i & = b_0 + b_1\text{Advertising}_i+ b_2\text{Airplay}_i + b_3\text{Image}_i + \varepsilon_i
\end{aligned}
$$

From a Bayesian perspective we can fit the model using either [default priors]{.kt}, which set distributions that represent very diffuse prior beliefs or [informative (subjective) priors]{.kt} that are distributions reflecting specific prior beliefs about the model parameters. We'll use the [rstanarm]{.pkg}  because it is a good gateway drug to more versatile (and complex) packages. The strength of [rstanarm]{.pkg} is that it uses sensible default priors, so it is straightforward to fit models with uninformative priors. However, the key strength of Bayesian statistics (in my opinion) is that you can set evidence-based (informative) priors that you update with the data that you collect. This undertaking is not a trivial: it requires a deeper understanding of the models than we can cover. Fortunately, [rstanarm]{.pkg} has limited, but straightforward, options for setting informative priors, meaning that we can dip our toes in the water.

To fit models using [rstanarm]{.pkg} requires using a lot of internal functions from the package, so it makes sense to use concise style rather than explicit for this package. Therefore, in your setup code chunk include:

```{r eval = F}
library(rstanarm)
```


### `r bmu()` Uninformatiove (default) priors [(C)]{.lbl}


The function we'll use from [rstanarm]{.pkg} is `stan_glm()` which is fairly similar to `lm()`. For a model that uses default priors it takes the general form:


```{r eval = F}
my_dp <- stan_glm(outcome ~ predictor_1 + predictor_2 + ... + predictor_n, data = my_tib)
```


We create a model by specifying a formula for the model and the data, just like in `lm()`. We store the model using an informative name; replace [my_dp]{.alt} with the name you want to give it (I use [_dp]{.alt} to mean 'default priors').

#### `r robot()` Code example

For the model in this chapter the code would be

```{r eval = F}
album_dp <- stan_glm(sales ~ adverts + airplay + image, data = album_tib)
```

We can extract information about the posterior distribution in the same way as for other models: we place the model into `model_parameters()` from [parameters]{.pkg}. For Bayesian models this function uses the bayestestR  [@bayestestR2019] package to get the information from the posterior distribution. 

This function has some options that apply only in the Bayesian context. In general:

```{r eval = F}
model_parameters(model = album_dp,
                 test = "pd",
                 null = 0)
```

The two unfamiliar arguments are

- [test = "pd"]{.alt}: by default, the function returns something known as the probability of direction (`pd`), which is an index of how likely it is that an effect goes in a certain direction (ranging from 50% to 100%). It is not an indicator of importance, because you can have effects that are, for example, definitely positive but trivially small. We want to look at Bayes Factors so we need to change this argument to [test = c("pd", "bf")]{.alt}, or just [test = "bf"]{.alt}.
- [null = 0]{.alt}: the null value for the parameters. In the models we fit in this book, this will usually be 0 (the default) meaning that the function returns the Bayes factors for each parameter against the null hypothesis that it is equal to zero.

#### `r robot()` Code example

We can, therefore, extract information form our model based on default priors using

```{r eval = F}
model_parameters(model = album_dp, test = c("pd", "bf"), null = 0) |> 
  display()
```

#### `r alien()` Alien coding challenge

Try fitting the model described above.

```{r rstan_dp, exercise = TRUE, exercise.lines = 10}

```

```{r rstan_dp-hint-1}
# first, fit the model (replace the xxxs)
album_dp <- stan_glm(xxx ~ xxx + xxx + xxx, data = xxx)
# now extract the model parameters
```

```{r rstan_dp-hint-2}
# fit the model (replace the xxxs)
album_dp <- stan_glm(sales ~ adverts + airplay + image, data = album_tib)
# extract the model parameters  (replace the xxxs)
model_parameters(xxx) |> xxx
```

```{r rstan_dp-solution}
# fit the model
album_dp <- stan_glm(sales ~ adverts + airplay + image, data = album_tib)
# extract the model parameters
model_parameters(model = album_dp, test = c("pd", "bf"), null = 0) |> 
  display()
```


The Bayesian parameter estimates based on default priors are in the column labelled [median]{.opt} (these values are the median of the posterior distribution), which are basically the same as the frequentist ones from `discovr_08`. This is because the default priors are very weak and uninformative so the estimates will be based mainly on the data (and for Frequentist models estimation is based entirely on the data). In fact, we can see the priors used in the final column. Each predictor had a prior centred at zero (no effect) with a standard deviation that varies according to the scale of measurement but is always large. For example, for image the distribution is so wide that almost any value of $b$ is plausible prior to fitting the model.

<div class="infobox">
  `r info()` **Bayesian models are based on sampling**

Bayesian estimation relies on sampling from the posterior distribution so your results will differ from mine. Therefore, the interpretation below is based on these model parameters:

```{r echo = F, results = "hide"}
album_dp <- stan_glm(sales ~ adverts + airplay + image, data = album_tib)
album_dp_par <- model_parameters(model = album_dp, test = c("pd", "bf"), null = 0) 
```

```{r echo = F}
display(album_dp_par)
```


</div>



```{r, echo = F}
bf_ad_num <- value_from_ez(album_dp_par, row = 2, value = "log_BF", exponentiate = T, as_number = T, digits = 2) |> format(big.mark = ",")
bf_air_num <- value_from_ez(album_dp_par, row = 3, value = "log_BF", exponentiate = T, as_number = T, digits = 2) |> format(big.mark = ",")
bf_ad <- value_from_ez(album_dp_par, row = 2, value = "log_BF", exponentiate = T, digits = 2, scientific = T)
bf_air <- value_from_ez(album_dp_par, row = 3, value = "log_BF", exponentiate = T, digits = 2, scientific = T)
bf_im <- value_from_ez(album_dp_par, row = 4, value = "log_BF", exponentiate = T, digits = 2)
```


Unlike our frequentist model, the 95% credible intervals (unlike confidence intervals) contain the true estimate with 0.95 probability. That is, with 0.95 probability, the true effect of advertising lies between a `r value_from_ez(album_dp_par, row = 2, value = "CI_low")` increase in sales for every pound spent, and a `r value_from_ez(album_dp_par, row = 2, value = "CI_high")` increase in sales for every pound spent (remember that both advertising and sales are measured in thousands of units). In other words, the true effect is weak.

The column labelled [BF]{.opt} contains the Bayes factors. For advertising the Bayes Factor is `r bf_ad`, which means that the data are `r bf_ad_num` times more likely under the alternative hypothesis (the $b$ for advertising is not zero) than under the null (the $b$ for advertising is zero). We should shift our belief about advertising being related to sales by a factor of `r bf_ad_num`! The Bayes factor for airplay is similarly huge (`r bf_air` or `r bf_air_num`). These values represent extreme evidence. The Bayes factor for image is a more modest `r bf_im` that is nevertheless strong evidence in favour of the alternative hypotheses.

### `r bmu()` Informative (subjective) priors [(D)]{.lbl}

This is great, but the real power of Bayesian models comes with setting informative priors. We have four parameters to think about: one for each of the three predictors and the intercept. [Technically we should set a prior for the error variance, but weâll use the default.] To set informative priors we would need to consider our expectations about the $b$s before we collected the data. To keep things as simple as we can we will consider only normally-distributed priors, but there are a wide range of other distributions you could use.

- `Intercept`: the intercept represents mean album sales when nothing is spent on advertising, there is no airplay and the band's image is rated at zero. It's like asking 'how many sales would we expect for a really uncool-looking band, if we did nothing'. Probably the record company has historic data on this. Let's assume that they know that you can expect 20,000 sales on average, but that it varies for different artists. They also know from historic data that the standard deviation is large, around 7,000. A reasonable prior might be a normal distribution centred on 20 (remember sales are expressed as 1000s) with a standard deviation of 7. This prior (, top-left) represents a belief that the mean number of sales for uncool bands with no promotion cannot be less than 0 (end of the left tail) or more than about 40 (end of the right tail) and will most likely be around 20 thousand. These beliefs seem reasonable, it would be odd, for example to have a prior in which negative sales (an impossibility) were likely.
- `advertising`: remember that this predictor was one about which there was prior information. Let's assume that based on past data the record company knew that historically, for every Â£1000 pounds they spend on advertising they can expect 1000 album sales. This equates to a b of 1. They also know that although spending money on advertising typically increases sales, they have been known to go down.  (top right) shows a prior distribution that reflects these prior beliefs: it is centred at 1 and ranges from about â0.5 to 2.5. Most of the distribution lies above zero, so we believe that advertising will most likely equate to more sales; however, because a small part of it lies below zero we are acknowledging the possibility that increased advertising might reduce sales.
- `airplay` and `image`: the 'new' features of our study were to measure airplay and quantify the band's image. In focus groups people tended to acknowledge that they would buy music if they were exposed to it and liked it, but some said that sometimes hearing a song made them less likely to buy it because they had heard it for free. Similarly, many of the group acknowledged that a cool image influenced whether they bought music but there was a lot of disagreement about this. Therefore, we're expecting these bs to be above zero but we're not too sure how big they might be. In particular, the focus group showed a wider variety of views about the importance of image. We want to set a weak priors for both to let the data do the work, but a weaker prior for image than airplay. Figure 4 shows some possible priors for the $b$s for `airplay` (bottom-left) and `image` (bottom-right). For airplay our prior says that we believe that the most likely value is $b$ = 5, meaning that for every addition airplay 5000 additional units would be sold, and that we think it highly unlikely (but possible) that sales could be negative. We also think there's a slim possibility that $b$ could be as much as 10. Similarly for image our prior says  that we believe that the most likely value is $b$ = 8, meaning that for every increase on the image scale 8000 additional units would be sold. This distribution is wider (and, therefore weaker) than for airplay though because we think that a fall in sales more likely (more of the distribution falls below 0) and we are more uncertain about the value in general (the distribution ranges from about -8 to 25.

```{r priorplots, echo = F, fig.cap = "Playing with priors"}
# prior for advertising
b1_gg <- ggplot(tibble(x = c(-1, 5)), aes(x=x)) +
  geom_function(fun = dnorm, args = list(mean = 1, sd = 0.5), colour = tol_blue, linewidth = line_width) +
  scale_x_continuous(breaks = seq(-1, 5, 1)) +
  geom_vline(xintercept = 0, colour = tol_bile, linetype = 2, linewidth = line_width) +
  geom_vline(xintercept = 1, colour = tol_rose, linewidth = line_width) +
  ggtitle('Prior for advertising') +
  theme_minimal()

# prior for airplay
b2_gg <- ggplot(tibble(x = c(-2, 12)), aes(x=x)) +
  geom_function(fun = dnorm, args = list(mean = 5, sd = 2), colour = tol_blue, linewidth = line_width) +
  scale_x_continuous(breaks = seq(-2, 12, 1)) +
  geom_vline(xintercept = 0, colour = tol_bile, linetype = 2, linewidth = line_width) +
  geom_vline(xintercept = 5, colour = tol_rose, linewidth = line_width) +
  ggtitle('Prior for airplay') +
  theme_minimal()

# prior for image
b3_gg <- ggplot(tibble(x = c(-10, 25)), aes(x=x)) +
  geom_function(fun = dnorm, args = list(mean = 8, sd = 5), colour = tol_blue, linewidth = line_width) +
  scale_x_continuous(breaks = seq(-10, 25, 5)) +
  geom_vline(xintercept = 0, colour = tol_bile, linetype = 2, linewidth = line_width) +
  geom_vline(xintercept = 8, colour = tol_rose, linewidth = line_width) +
  ggtitle('Prior for image') +
  theme_minimal()

# prior for intercept
b0_gg <- ggplot(tibble(x = c(-10, 50)), aes(x=x)) +
  geom_function(fun = dnorm, args = list(mean = 20, sd = 7), colour = tol_blue, linewidth = line_width) +
  scale_x_continuous(breaks = seq(-10, 50, 5)) +
  geom_vline(xintercept = 0, colour = tol_bile, linetype = 2, linewidth = line_width) +
  geom_vline(xintercept = 20, colour = tol_rose, linewidth = line_width) +
  ggtitle('Prior for intercept') +
  theme_minimal()

b0_gg +b1_gg + b2_gg + b3_gg + plot_layout(nrow = 2)
```


#### `r robot()` Code example

To include informative priors we add two arguments:

- [prior]{.alt} sets the prior distributions for the $b$s associated with each predictor
- [prior_intercept]{.alt} sets the prior distribution for the intercept ($b_0$). The function takes the general form:

```{r eval = F}
my_rstn <- stan_glm(outcome ~ predictor_1 + predictor_2 + â¦ + predictor_n,
                    data = my_tib,
                    prior = normal(location = c(mean_1, mean_2, â¦ mean_n),
                                   scale = c(sd_1, sd_2, â¦ sd_n)),
                    prior_intercept = normal(location = mean_0, scale = sd_0))
```


As with the previous model, we give it a name, define it using the standard formula notation and specify the data. The prior argument is for specifying the priors for any predictors. In [rstanarm]{.pkg} the priors must have the same distribution, which is why all our priors are normally distributed. To define the priors we use a function for the distribution we want, in this case `normal()`. There are other functions we could use, but we won't cover them. Within `normal()` we supply the means of each prior distribution as the location, and the standard deviations as the scale. Our priors for advertising, airplay and image respectively were 1, 5, and 8, with the corresponding standard deviations of 0.5, 2 and 5. Therefore, we'd specify these as

```{r eval = F}
prior = normal(location = c(1, 5, 8), scale = c(0.5, 2, 5))
```

The first values in [location]{.alt} and [scale]{.alt} are the mean and standard deviation of the prior for the first predictor in your formula and so on. We specify the prior for the intercept in a similar way using the [prior_intercept]{.alt} argument, but need only to supply a single value for the location (mean) and scale (standard deviation). Putting this together, our code to fit the model using our informative priors would be:


```{r eval = F}
album_rstn <- stan_glm(sales ~ adverts + airplay + image,
                      data = album_tib,
                      prior = normal(location = c(1, 5, 8), scale = c(0.5, 2, 5)),
                      prior_intercept = normal(location = 20, scale = 7))
```


We'd extract the model information using the same code as before (just changing the model name).

#### `r alien()` Alien coding challenge

Try fitting the model with informative priors described above.

```{r rstan_ip, exercise = TRUE, exercise.lines = 10}

```

```{r rstan_ip-hint-1}
# first, fit the model (replace the xxxs)
album_rstn <- stan_glm(sales ~ adverts + airplay + image,
                      data = album_tib,
                      prior = normal(location = c(1, 5, 8), scale = c(0.5, 2, 5)),
                      prior_intercept = normal(location = 20, scale = 7))
# now extract the model parameters
```


```{r rstan_ip-solution}
# fit the model
album_rstn <- stan_glm(sales ~ adverts + airplay + image,
                      data = album_tib,
                      prior = normal(location = c(1, 5, 8), scale = c(0.5, 2, 5)),
                      prior_intercept = normal(location = 20, scale = 7))
# extract the model parameters
model_parameters(model = album_rstn, test = c("pd", "bf"), null = 0) |> 
  display()
```


Comparing the output to that of the previous model reveals the effect of the priors on the parameter estimates (and note the [Prior]{.opt} column has changed to reflect the priors we set). The estimates for the intercept has changed a lot because our prior was a lot narrower and located much closer to zero resulting in a more negative estimate. The prior has dragged the estimate down. The credibility interval has got wider because the prior is a little at odds with the data. The estimates of the other $b$s haven't changed a lot because the priors were broadly in line with the data (and for `airplay` and `image` were quite weak anyway). We can also see the effect of the priors on the Bayes factors. They have all decreased substantially but are nevertheless very large! Remember, you wouldn't fit both models and compare, you'd generally fit the model with informative priors and interpret it.


<div class="infobox">
  <img src="./images/discovr_hex.png" alt="discovr package hex sticker, female space pirate with gun. Gunsmoke forms the letter R." style="width:100px;height:116px;" class = "img_left">
  
  **A message from Mae Jemstone:**
  
  Hopefully you are not Bayes-ed and confused after your flight into the black hole of Bayesian approaches to model fitting. This is the final step in your intergalactic journey to become a fully fledged space pirate and you aced it! Well done, congratulations and welcome to my team! You now have the power to fight opinion, misinformation and rhetoric with data and critical thinking. Now go out into the world and use your new found powers for good. Be kind, be compassionate and be data-driven. 
</div>


## Resources/References {data-progressive=FALSE}

```{r, child = "resources.Rmd"}

```


### References
